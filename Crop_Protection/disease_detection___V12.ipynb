{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yy3vDAofi1ki"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "## Version-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mQRvfTsqSTHv"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.move('/content/NewPlantVillage','/content/drive/MyDrive/major-proj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rVj_gwkntwoG"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "zip_file_path = 'PlantVillage.zip'\n",
    "extract_folder_path = ''\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lS4SUgEtuiSW"
   },
   "outputs": [],
   "source": [
    "# !unzip /PlantVillage.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d56CFa05uiOy"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Replace 'path_to_your_image.jpg' with the actual path to your image\n",
    "display(Image(filename='PlantVillage/Pepper__bell___Bacterial_spot/0022d6b7-d47c-4ee2-ae9a-392a53f48647___JR_B.Spot 8964.JPG'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JyoRpf-WuiFB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s8AptPvMpxVh"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define constants\n",
    "img_width, img_height = 225, 225\n",
    "train_data_dir = '/content/DATASET/Training'\n",
    "test_data_dir = '/content/DATASET/Testing'\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "num_classes = 131  # Number of disease classes\n",
    "\n",
    "# Preprocess and augment data\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "#test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vh-_SUenxWvT"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model using generators\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=epochs,\n",
    "    validation_data=train_generator,\n",
    "    validation_steps=len(train_generator)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WHnSnZdP2LhH"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Path to your new image for prediction\n",
    "new_image_path = '/content/DATASET/Testing/armyworm/jpg_10 - Copy.jpg'\n",
    "\n",
    "# Load and preprocess the image for prediction\n",
    "img = image.load_img(new_image_path, target_size=(img_width, img_height))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array /= 255.0  # Rescale to match the training data preprocessing\n",
    "\n",
    "# Perform prediction\n",
    "prediction = model.predict(img_array)\n",
    "\n",
    "# Decode the prediction\n",
    "predicted_class = np.argmax(prediction)\n",
    "print(f\"Predicted class index: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_XRu3fX4WTh"
   },
   "outputs": [],
   "source": [
    "# Map numerical labels to class names\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "\n",
    "# # Perform prediction\n",
    "# predicted_class_n = np.argmax(predict)\n",
    "predicted_class_name = class_names[predicted_class]\n",
    "\n",
    "print(f\"Predicted class: {predicted_class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CHous-rN1vBL"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {accuracy[1] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yOZsXs2xA2qW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nt5TZ-DniWzk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g0A6eKeNiWwF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VZUKopeNiWtn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ELsOFVaiWqv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IPQjKyXiiWnV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uGOBvDadiWkG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y8wW6iCdiWgz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IMDKKP1miWeJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jaRQlF9biWXP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qmUMrTKKiWPP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J058v-hRiWLx"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree('PlantVillage1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ubShZ9mutwoQ"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "ZipFile('PlantVillage1.zip').extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d7w7yVJK544D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aF01BZB_ibBU"
   },
   "source": [
    "#**Version-2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tuOK4QyRNf33"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QqRtDNgN56lK"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hVOC0swQ6IIW"
   },
   "outputs": [],
   "source": [
    "!unzip /content/drive/MyDrive/major-proj/NewPlantVillage.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kvwcEMa7Rvzn"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Replace 'path_to_your_image.jpg' with the actual path to your image\n",
    "display(Image(filename='PlantVillage/Pepper__bell___Bacterial_spot/0022d6b7-d47c-4ee2-ae9a-392a53f48647___JR_B.Spot 8964.JPG'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XXwjSohFA2m3"
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "shutil.rmtree('NewPlantVillage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9PUJ9_QbtwoQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Path to the directory containing the files\n",
    "directory = 'PlantVillage1'\n",
    "\n",
    "# Iterate through the files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    for file in os.listdir(os.path.join(directory,filename)):\n",
    "        # Check if the file is an image (you can customize the extensions here)\n",
    "        if not (os.path.join(directory,filename,file).endswith('.JPG') or os.path.join(directory,filename,file).endswith('.jpg') or os.path.join(directory,filename,file).endswith('.png')or os.path.join(directory,filename,file).endswith('.jpeg')):\n",
    "            # Delete the file if it's not an image\n",
    "            os.remove(os.path.join(directory,filename,file))\n",
    "            print('unknown file: ',file)\n",
    "        if os.path.join(directory,filename,file).endswith('.JPG'):\n",
    "            name ,_ = os.path.splitext(file)\n",
    "            new_filename = os.path.join(directory,filename,name+'.jpg')\n",
    "            os.rename(os.path.join(directory,filename,file), new_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XeLkpgentwoR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VdwW60TXtwoR"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "# Check images in a directory\n",
    "directory = 'PlantVillage1'\n",
    "count_test,count_train = 0,0\n",
    "for folder in os.listdir(directory):\n",
    "    for filename in os.listdir(os.path.join(directory,folder)):\n",
    "        file_path = os.path.join(directory,folder,filename)\n",
    "        try:\n",
    "            Image.open(file_path).verify()\n",
    "        except:\n",
    "            #remove if there is any file other than image\n",
    "            os.remove(file_path)\n",
    "            count_test += 1\n",
    "count_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OZAsxbrAA2iW"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "# Remove the Testing folder\n",
    "\n",
    "\n",
    "# Define paths\n",
    "train_data_dir = 'PlantVillage1'\n",
    "new_train_dir = 'NewPlantVillage'\n",
    "\n",
    "# Create new directories for splitting data\n",
    "os.makedirs(new_train_dir + '/Train')\n",
    "#os.makedirs(new_train_dir + '/Validation')\n",
    "os.makedirs(new_train_dir + '/Test')\n",
    "\n",
    "# Splitting data into train, validation, and test sets\n",
    "\n",
    "subfolders = os.listdir(train_data_dir)\n",
    "for folder in subfolders:\n",
    "    os.makedirs(new_train_dir + '/Test/'+folder)\n",
    "    os.makedirs(new_train_dir + '/Train/'+folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RtR3PqzjtwoS"
   },
   "outputs": [],
   "source": [
    " # os.makedirs(new_train_dir + '/Validate/'+folder)\n",
    "for folder in subfolders:\n",
    "    files = os.listdir(os.path.join(train_data_dir, folder))\n",
    "    train_files, test_files = train_test_split(files, train_size=0.8, random_state=42)\n",
    "    #val_files, test_files = train_test_split(test_val_files, train_size=0.5, random_state=42)\n",
    "    for i,file in enumerate(train_files):\n",
    "        try:\n",
    "            Image.open(file).verify()\n",
    "            shutil.copy(os.path.join(train_data_dir, folder, file), os.path.join(new_train_dir, 'Train', folder))\n",
    "        except:\n",
    "            print(folder,\" \",file)\n",
    "    for i,file in enumerate(test_files):\n",
    "        try:\n",
    "            Image.open(file).verify()\n",
    "            shutil.copy(os.path.join(train_data_dir, folder, file), os.path.join(new_train_dir, 'Test', folder))\n",
    "        except:\n",
    "            print(folder,\" \",file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYskZFQdKikK"
   },
   "source": [
    "###All preprocessing the data already done above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgUYEMczNSoy"
   },
   "source": [
    "###Data Generator Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wGGNjh23uJOj"
   },
   "outputs": [],
   "source": [
    "# !unzip /content/NewPlantVillage.zip\n",
    "!unzip /content/drive/MyDrive/major-proj/NewPlantVillage.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dFOYkGAMHdXk"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "# After training and validation, evaluate on the new test set\n",
    "\n",
    "# Define constants\n",
    "img_width, img_height = 256, 256\n",
    "train_data_dir = 'NewPlantVillage/Train'\n",
    "test_data_dir = 'NewPlantVillage/Test'\n",
    "\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "num_classes = 15  # Number of disease classes\n",
    "\n",
    "\n",
    "# Preprocess and augment data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255#,\n",
    "    #validation_split=0.1  # Split 10% for validation\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMz-mVmIM29h"
   },
   "source": [
    "###**Normal** model1-Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zR1vejbhDnks"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512*2, activation='relu'))\n",
    "#model.add(Dense(512*, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model using generators\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=len(test_generator)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01LqcVAUNELR"
   },
   "source": [
    "###Model Building to run under GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "64IN8T3R77q0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\RAMU GOPI\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Num GPUs Available:  0\n",
      "Device name: \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check available devices\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Device name:\", tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1N-ONSsL7s7U"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the CNN model using TensorFlow's Keras\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "# model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "# model.add(tf.keras.layers.Dense(512*2, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dense(512*, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model using generators\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=len(test_generator)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4WkMbU5Fzoy"
   },
   "source": [
    "###model_saving V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ImJ8jPwhCW3f"
   },
   "outputs": [],
   "source": [
    "#saving to drive\n",
    "model.save('/content/drive/MyDrive/major-proj/disease_detect_V10')\n",
    "model.save_weights('/content/drive/MyDrive/major-proj/disease_detect_weights_V10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "85qeKPwsDwfK"
   },
   "outputs": [],
   "source": [
    "load_model2 = tf.keras.models.load_model('/content/drive/MyDrive/major-proj/disease_detect_V10')\n",
    "load_model2.load_weights('/content/drive/MyDrive/major-proj/disease_detect_weights_V10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fyx4CYcxEYgS"
   },
   "outputs": [],
   "source": [
    "# Perform prediction\n",
    "prediction = load_model2.predict(img_array)\n",
    "\n",
    "# Decode the prediction\n",
    "predicted_class = np.argmax(prediction)\n",
    "print(f\"Predicted class index: {predicted_class}\")\n",
    "# Map numerical labels to class names\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "\n",
    "# # Perform prediction\n",
    "# predicted_class_n = np.argmax(predict)\n",
    "predicted_class_name = class_names[predicted_class]\n",
    "\n",
    "print(f\"Predicted class: {predicted_class_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bg3VkstGBMZ"
   },
   "source": [
    "###Model_save V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prKOdbHmJXE8"
   },
   "outputs": [],
   "source": [
    "#saving to drive\n",
    "model.save('/content/drive/MyDrive/major-proj/disease_detect_V10.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p7oDmPa2E_AP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqFMlgGDFTbV"
   },
   "outputs": [],
   "source": [
    "# Perform prediction\n",
    "load_model2 = tf.keras.models.load_model('/content/drive/MyDrive/major-proj/disease_detect_V10.keras')\n",
    "prediction = load_model2.predict(img_array)\n",
    "\n",
    "# Decode the prediction\n",
    "predicted_class = np.argmax(prediction)\n",
    "print(f\"Predicted class index: {predicted_class}\")\n",
    "# Map numerical labels to class names\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "\n",
    "# # Perform prediction\n",
    "# predicted_class_n = np.argmax(predict)\n",
    "predicted_class_name = class_names[predicted_class]\n",
    "\n",
    "print(f\"Predicted class: {predicted_class_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPQ6s90wGEof"
   },
   "source": [
    "###Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rPLz0vjuA2fj"
   },
   "outputs": [],
   "source": [
    "accuracy = model.evaluate(test_generator)\n",
    "print(f\"New Test Accuracy: {accuracy[1] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pmptAtPVA2c0"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Path to your new image for prediction\n",
    "new_image_path = '/content/NewPlantVillage/Test/Tomato_Early_blight/023fe2d4-6e1d-40ce-99ae-85ba90f436ff___RS_Erly.B 6354.jpg'\n",
    "\n",
    "# Load and preprocess the image for prediction\n",
    "img = image.load_img(new_image_path, target_size=(img_width, img_height))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array /= 255.0  # Rescale to match the training data preprocessing\n",
    "\n",
    "# Perform prediction\n",
    "prediction = model.predict(img_array)\n",
    "\n",
    "# Decode the prediction\n",
    "predicted_class = np.argmax(prediction)\n",
    "print(f\"Predicted class index: {predicted_class}\")\n",
    "# Map numerical labels to class names\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "\n",
    "# # Perform prediction\n",
    "# predicted_class_n = np.argmax(predict)\n",
    "predicted_class_name = class_names[predicted_class]\n",
    "\n",
    "print(f\"Predicted class: {predicted_class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DRpRANkphDMR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7onkQ51DSQTP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
