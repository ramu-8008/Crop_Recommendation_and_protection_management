{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7a801bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "55fe92b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>State_Name</th>\n",
       "      <th>Crop_Type</th>\n",
       "      <th>Crop</th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>pH</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>temperature</th>\n",
       "      <th>Area_in_hectares</th>\n",
       "      <th>Production_in_tons</th>\n",
       "      <th>Yield_ton_per_hec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>andhra pradesh</td>\n",
       "      <td>kharif</td>\n",
       "      <td>cotton</td>\n",
       "      <td>120</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>5.46</td>\n",
       "      <td>654.34</td>\n",
       "      <td>29.266667</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>9400.0</td>\n",
       "      <td>1.287671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>andhra pradesh</td>\n",
       "      <td>kharif</td>\n",
       "      <td>horsegram</td>\n",
       "      <td>20</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>6.18</td>\n",
       "      <td>654.34</td>\n",
       "      <td>29.266667</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.303030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>andhra pradesh</td>\n",
       "      <td>kharif</td>\n",
       "      <td>jowar</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>5.42</td>\n",
       "      <td>654.34</td>\n",
       "      <td>29.266667</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>1.009901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>andhra pradesh</td>\n",
       "      <td>kharif</td>\n",
       "      <td>maize</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>5.62</td>\n",
       "      <td>654.34</td>\n",
       "      <td>29.266667</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>1.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>andhra pradesh</td>\n",
       "      <td>kharif</td>\n",
       "      <td>moong</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>5.68</td>\n",
       "      <td>654.34</td>\n",
       "      <td>29.266667</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      State_Name Crop_Type       Crop    N   P   K    pH  \\\n",
       "0           0  andhra pradesh    kharif     cotton  120  40  20  5.46   \n",
       "1           1  andhra pradesh    kharif  horsegram   20  60  20  6.18   \n",
       "2           2  andhra pradesh    kharif      jowar   80  40  40  5.42   \n",
       "3           3  andhra pradesh    kharif      maize   80  40  20  5.62   \n",
       "4           4  andhra pradesh    kharif      moong   20  40  20  5.68   \n",
       "\n",
       "   rainfall  temperature  Area_in_hectares  Production_in_tons  \\\n",
       "0    654.34    29.266667            7300.0              9400.0   \n",
       "1    654.34    29.266667            3300.0              1000.0   \n",
       "2    654.34    29.266667           10100.0             10200.0   \n",
       "3    654.34    29.266667            2800.0              4900.0   \n",
       "4    654.34    29.266667            1300.0               500.0   \n",
       "\n",
       "   Yield_ton_per_hec  \n",
       "0           1.287671  \n",
       "1           0.303030  \n",
       "2           1.009901  \n",
       "3           1.750000  \n",
       "4           0.384615  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"D:/SEM/7th sem/major project/review-2.0/archive10MB/Crop_production.csv\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "77a796ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'State_Name', 'Crop_Type', 'Crop', 'N', 'P', 'K', 'pH',\n",
       "       'rainfall', 'temperature', 'Area_in_hectares', 'Production_in_tons',\n",
       "       'Yield_ton_per_hec'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "780add0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_Name</th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>pH</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>temperature</th>\n",
       "      <th>Crop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>andhra pradesh</td>\n",
       "      <td>120</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>5.46</td>\n",
       "      <td>654.34</td>\n",
       "      <td>29.266667</td>\n",
       "      <td>cotton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>andhra pradesh</td>\n",
       "      <td>20</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>6.18</td>\n",
       "      <td>654.34</td>\n",
       "      <td>29.266667</td>\n",
       "      <td>horsegram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andhra pradesh</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>5.42</td>\n",
       "      <td>654.34</td>\n",
       "      <td>29.266667</td>\n",
       "      <td>jowar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>andhra pradesh</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>5.62</td>\n",
       "      <td>654.34</td>\n",
       "      <td>29.266667</td>\n",
       "      <td>maize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>andhra pradesh</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>5.68</td>\n",
       "      <td>654.34</td>\n",
       "      <td>29.266667</td>\n",
       "      <td>moong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99844</th>\n",
       "      <td>west bengal</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>6.70</td>\n",
       "      <td>152.54</td>\n",
       "      <td>22.280000</td>\n",
       "      <td>wheat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99845</th>\n",
       "      <td>west bengal</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>5.68</td>\n",
       "      <td>182.50</td>\n",
       "      <td>29.200000</td>\n",
       "      <td>maize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99846</th>\n",
       "      <td>west bengal</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>5.64</td>\n",
       "      <td>182.50</td>\n",
       "      <td>29.200000</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99847</th>\n",
       "      <td>west bengal</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>5.42</td>\n",
       "      <td>152.54</td>\n",
       "      <td>22.280000</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99848</th>\n",
       "      <td>west bengal</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>6.54</td>\n",
       "      <td>152.54</td>\n",
       "      <td>22.280000</td>\n",
       "      <td>sesamum</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99849 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           State_Name    N   P   K    pH  rainfall  temperature       Crop\n",
       "0      andhra pradesh  120  40  20  5.46    654.34    29.266667     cotton\n",
       "1      andhra pradesh   20  60  20  6.18    654.34    29.266667  horsegram\n",
       "2      andhra pradesh   80  40  40  5.42    654.34    29.266667      jowar\n",
       "3      andhra pradesh   80  40  20  5.62    654.34    29.266667      maize\n",
       "4      andhra pradesh   20  40  20  5.68    654.34    29.266667      moong\n",
       "...               ...  ...  ..  ..   ...       ...          ...        ...\n",
       "99844     west bengal   60  30  30  6.70    152.54    22.280000      wheat\n",
       "99845     west bengal   80  40  20  5.68    182.50    29.200000      maize\n",
       "99846     west bengal   80  40  40  5.64    182.50    29.200000       rice\n",
       "99847     west bengal   80  40  40  5.42    152.54    22.280000       rice\n",
       "99848     west bengal   30  15  30  6.54    152.54    22.280000    sesamum\n",
       "\n",
       "[99849 rows x 8 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['State_Name', 'N', 'P', 'K', 'pH', 'rainfall', 'temperature', 'Crop']\n",
    "data = data[columns]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3c31dcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of dataset:  (99849, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of dataset: \",data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ff4bfe9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cotton', 'horsegram', 'jowar', 'maize', 'moong', 'ragi', 'rice',\n",
       "       'sunflower', 'wheat', 'sesamum', 'soyabean', 'rapeseed', 'jute',\n",
       "       'arecanut', 'onion', 'potato', 'sweetpotato', 'tapioca',\n",
       "       'turmeric', 'barley', 'banana', 'coriander', 'garlic',\n",
       "       'blackpepper', 'cardamom', 'cashewnuts', 'blackgram', 'coffee',\n",
       "       'ladyfinger', 'brinjal', 'cucumber', 'grapes', 'mango', 'orange',\n",
       "       'papaya', 'tomato', 'cabbage', 'bottlegourd', 'pineapple',\n",
       "       'carrot', 'radish', 'bittergourd', 'drumstick', 'jackfruit',\n",
       "       'cauliflower', 'watermelon', 'ashgourd', 'beetroot', 'pomegranate',\n",
       "       'ridgegourd', 'pumpkin', 'apple', 'ginger'], dtype=object)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Crop'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c19c7320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_Name</th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>pH</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>temperature</th>\n",
       "      <th>Crop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17726</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>140</td>\n",
       "      <td>5.86</td>\n",
       "      <td>1925.68</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31401</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>140</td>\n",
       "      <td>5.82</td>\n",
       "      <td>3322.06</td>\n",
       "      <td>27.036364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31400</th>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>5.42</td>\n",
       "      <td>1925.68</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31399</th>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "      <td>5.94</td>\n",
       "      <td>3322.06</td>\n",
       "      <td>27.036364</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31398</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>5.14</td>\n",
       "      <td>3322.06</td>\n",
       "      <td>27.036364</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39797</th>\n",
       "      <td>32</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>5.60</td>\n",
       "      <td>1166.94</td>\n",
       "      <td>28.333333</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39798</th>\n",
       "      <td>32</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>5.54</td>\n",
       "      <td>1166.94</td>\n",
       "      <td>28.333333</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39799</th>\n",
       "      <td>32</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>5.42</td>\n",
       "      <td>1166.94</td>\n",
       "      <td>28.333333</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39791</th>\n",
       "      <td>32</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>5.40</td>\n",
       "      <td>182.50</td>\n",
       "      <td>29.200000</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99848</th>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>6.54</td>\n",
       "      <td>152.54</td>\n",
       "      <td>22.280000</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99849 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       State_Name    N   P    K    pH  rainfall  temperature  Crop\n",
       "17726           0  100  40  140  5.86   1925.68    27.000000     1\n",
       "31401           0  100  40  140  5.82   3322.06    27.036364     1\n",
       "31400           0   80  40   40  5.42   1925.68    27.000000    42\n",
       "31399           0   70  40   60  5.94   3322.06    27.036364    14\n",
       "31398           0  100  60   50  5.14   3322.06    27.036364     8\n",
       "...           ...  ...  ..  ...   ...       ...          ...   ...\n",
       "39797          32   80  40   40  5.60   1166.94    28.333333    42\n",
       "39798          32   80  40   40  5.54   1166.94    28.333333    27\n",
       "39799          32   80  40   20  5.42   1166.94    28.333333    29\n",
       "39791          32   80  40   40  5.40    182.50    29.200000    42\n",
       "99848          32   30  15   30  6.54    152.54    22.280000    44\n",
       "\n",
       "[99849 rows x 8 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#doing one hot encoding 'label' column\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "data['Crop'] = encoder.fit_transform(data['Crop'])\n",
    "encoder2 = LabelEncoder()\n",
    "data['State_Name'] = encoder2.fit_transform(data['State_Name'])\n",
    "data = data.sort_values(by = 'State_Name')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3ac64ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data#.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "755e5985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  Index(['State_Name', 'N', 'P', 'K', 'pH', 'rainfall', 'temperature'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_Name</th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>pH</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17726</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>140</td>\n",
       "      <td>5.86</td>\n",
       "      <td>1925.68</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31401</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>140</td>\n",
       "      <td>5.82</td>\n",
       "      <td>3322.06</td>\n",
       "      <td>27.036364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31400</th>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>5.42</td>\n",
       "      <td>1925.68</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31399</th>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "      <td>5.94</td>\n",
       "      <td>3322.06</td>\n",
       "      <td>27.036364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31398</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>5.14</td>\n",
       "      <td>3322.06</td>\n",
       "      <td>27.036364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39797</th>\n",
       "      <td>32</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>5.60</td>\n",
       "      <td>1166.94</td>\n",
       "      <td>28.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39798</th>\n",
       "      <td>32</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>5.54</td>\n",
       "      <td>1166.94</td>\n",
       "      <td>28.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39799</th>\n",
       "      <td>32</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>5.42</td>\n",
       "      <td>1166.94</td>\n",
       "      <td>28.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39791</th>\n",
       "      <td>32</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>5.40</td>\n",
       "      <td>182.50</td>\n",
       "      <td>29.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99848</th>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>6.54</td>\n",
       "      <td>152.54</td>\n",
       "      <td>22.280000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99849 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       State_Name    N   P    K    pH  rainfall  temperature\n",
       "17726           0  100  40  140  5.86   1925.68    27.000000\n",
       "31401           0  100  40  140  5.82   3322.06    27.036364\n",
       "31400           0   80  40   40  5.42   1925.68    27.000000\n",
       "31399           0   70  40   60  5.94   3322.06    27.036364\n",
       "31398           0  100  60   50  5.14   3322.06    27.036364\n",
       "...           ...  ...  ..  ...   ...       ...          ...\n",
       "39797          32   80  40   40  5.60   1166.94    28.333333\n",
       "39798          32   80  40   40  5.54   1166.94    28.333333\n",
       "39799          32   80  40   20  5.42   1166.94    28.333333\n",
       "39791          32   80  40   40  5.40    182.50    29.200000\n",
       "99848          32   30  15   30  6.54    152.54    22.280000\n",
       "\n",
       "[99849 rows x 7 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('Crop',axis = 1)\n",
    "Y = df['Crop']\n",
    "print(\"x: \",X.columns)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7b4a75b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X,Y, train_size = 0.8,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151724fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1756f753",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ea52d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train size : 559153\n",
      "x_test size : 139790\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train size :\",x_train.size)\n",
    "print(\"x_test size :\",x_test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ccddefe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2497/2497 [==============================] - 12s 4ms/step - loss: 0.3477 - accuracy: 0.8902 - val_loss: 0.1400 - val_accuracy: 0.9306\n",
      "Epoch 2/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.1313 - accuracy: 0.9341 - val_loss: 0.1255 - val_accuracy: 0.9356\n",
      "Epoch 3/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.1231 - accuracy: 0.9357 - val_loss: 0.1234 - val_accuracy: 0.9343\n",
      "Epoch 4/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.1178 - accuracy: 0.9369 - val_loss: 0.1153 - val_accuracy: 0.9385\n",
      "Epoch 5/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.1147 - accuracy: 0.9381 - val_loss: 0.1165 - val_accuracy: 0.9371\n",
      "Epoch 6/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.1090 - accuracy: 0.9397 - val_loss: 0.1029 - val_accuracy: 0.9407\n",
      "Epoch 7/100\n",
      "2497/2497 [==============================] - 10s 4ms/step - loss: 0.1066 - accuracy: 0.9399 - val_loss: 0.1039 - val_accuracy: 0.9424\n",
      "Epoch 8/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.1036 - accuracy: 0.9419 - val_loss: 0.1007 - val_accuracy: 0.9419\n",
      "Epoch 9/100\n",
      "2497/2497 [==============================] - 10s 4ms/step - loss: 0.1038 - accuracy: 0.9415 - val_loss: 0.1065 - val_accuracy: 0.9401\n",
      "Epoch 10/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.1024 - accuracy: 0.9415 - val_loss: 0.1019 - val_accuracy: 0.9407\n",
      "Epoch 11/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.1013 - accuracy: 0.9427 - val_loss: 0.1244 - val_accuracy: 0.9373\n",
      "Epoch 12/100\n",
      "2497/2497 [==============================] - 10s 4ms/step - loss: 0.1004 - accuracy: 0.9432 - val_loss: 0.0990 - val_accuracy: 0.9422\n",
      "Epoch 13/100\n",
      "2497/2497 [==============================] - 10s 4ms/step - loss: 0.1016 - accuracy: 0.9429 - val_loss: 0.0987 - val_accuracy: 0.9421\n",
      "Epoch 14/100\n",
      "2497/2497 [==============================] - 10s 4ms/step - loss: 0.0997 - accuracy: 0.9431 - val_loss: 0.1067 - val_accuracy: 0.9415\n",
      "Epoch 15/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0986 - accuracy: 0.9438 - val_loss: 0.0981 - val_accuracy: 0.9434\n",
      "Epoch 16/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.1003 - accuracy: 0.9429 - val_loss: 0.0963 - val_accuracy: 0.9435\n",
      "Epoch 17/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0993 - accuracy: 0.9427 - val_loss: 0.0987 - val_accuracy: 0.9416\n",
      "Epoch 18/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0975 - accuracy: 0.9439 - val_loss: 0.0974 - val_accuracy: 0.9440\n",
      "Epoch 19/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0987 - accuracy: 0.9431 - val_loss: 0.0981 - val_accuracy: 0.9411\n",
      "Epoch 20/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0973 - accuracy: 0.9441 - val_loss: 0.0969 - val_accuracy: 0.9455\n",
      "Epoch 21/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0975 - accuracy: 0.9435 - val_loss: 0.0966 - val_accuracy: 0.9438\n",
      "Epoch 22/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0990 - accuracy: 0.9438 - val_loss: 0.0963 - val_accuracy: 0.9428\n",
      "Epoch 23/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0967 - accuracy: 0.9437 - val_loss: 0.0978 - val_accuracy: 0.9434\n",
      "Epoch 24/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0975 - accuracy: 0.9441 - val_loss: 0.0963 - val_accuracy: 0.9434\n",
      "Epoch 25/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0962 - accuracy: 0.9441 - val_loss: 0.0946 - val_accuracy: 0.9439\n",
      "Epoch 26/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0967 - accuracy: 0.9444 - val_loss: 0.1011 - val_accuracy: 0.9439\n",
      "Epoch 27/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0977 - accuracy: 0.9442 - val_loss: 0.0969 - val_accuracy: 0.9442\n",
      "Epoch 28/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0962 - accuracy: 0.9440 - val_loss: 0.0949 - val_accuracy: 0.9436\n",
      "Epoch 29/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0956 - accuracy: 0.9444 - val_loss: 0.0949 - val_accuracy: 0.9430\n",
      "Epoch 30/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0979 - accuracy: 0.9436 - val_loss: 0.0948 - val_accuracy: 0.9447\n",
      "Epoch 31/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0956 - accuracy: 0.9451 - val_loss: 0.0962 - val_accuracy: 0.9446\n",
      "Epoch 32/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0959 - accuracy: 0.9443 - val_loss: 0.0941 - val_accuracy: 0.9437\n",
      "Epoch 33/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0958 - accuracy: 0.9445 - val_loss: 0.1000 - val_accuracy: 0.9433\n",
      "Epoch 34/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0963 - accuracy: 0.9450 - val_loss: 0.0970 - val_accuracy: 0.9452\n",
      "Epoch 35/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0949 - accuracy: 0.9447 - val_loss: 0.0956 - val_accuracy: 0.9423\n",
      "Epoch 36/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0991 - accuracy: 0.9443 - val_loss: 0.1012 - val_accuracy: 0.9425\n",
      "Epoch 37/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0949 - accuracy: 0.9452 - val_loss: 0.0963 - val_accuracy: 0.9412\n",
      "Epoch 38/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0947 - accuracy: 0.9442 - val_loss: 0.0939 - val_accuracy: 0.9446\n",
      "Epoch 39/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0951 - accuracy: 0.9447 - val_loss: 0.0955 - val_accuracy: 0.9447\n",
      "Epoch 40/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0956 - accuracy: 0.9451 - val_loss: 0.1034 - val_accuracy: 0.9428\n",
      "Epoch 41/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0952 - accuracy: 0.9453 - val_loss: 0.0960 - val_accuracy: 0.9428\n",
      "Epoch 42/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0965 - accuracy: 0.9448 - val_loss: 0.1049 - val_accuracy: 0.9431\n",
      "Epoch 43/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0950 - accuracy: 0.9444 - val_loss: 0.0949 - val_accuracy: 0.9434\n",
      "Epoch 44/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0950 - accuracy: 0.9447 - val_loss: 0.0954 - val_accuracy: 0.9449\n",
      "Epoch 45/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0951 - accuracy: 0.9447 - val_loss: 0.0946 - val_accuracy: 0.9439\n",
      "Epoch 46/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0951 - accuracy: 0.9453 - val_loss: 0.0942 - val_accuracy: 0.9443\n",
      "Epoch 47/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0956 - accuracy: 0.9446 - val_loss: 0.0937 - val_accuracy: 0.9447\n",
      "Epoch 48/100\n",
      "2497/2497 [==============================] - 10s 4ms/step - loss: 0.0944 - accuracy: 0.9454 - val_loss: 0.0947 - val_accuracy: 0.9452\n",
      "Epoch 49/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0944 - accuracy: 0.9447 - val_loss: 0.0941 - val_accuracy: 0.9433\n",
      "Epoch 50/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0977 - accuracy: 0.9450 - val_loss: 0.0954 - val_accuracy: 0.9441\n",
      "Epoch 51/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0947 - accuracy: 0.9456 - val_loss: 0.0954 - val_accuracy: 0.9440\n",
      "Epoch 52/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0944 - accuracy: 0.9449 - val_loss: 0.0960 - val_accuracy: 0.9436\n",
      "Epoch 53/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0940 - accuracy: 0.9456 - val_loss: 0.0955 - val_accuracy: 0.9442\n",
      "Epoch 54/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0957 - accuracy: 0.9455 - val_loss: 0.0934 - val_accuracy: 0.9444\n",
      "Epoch 55/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0941 - accuracy: 0.9453 - val_loss: 0.0943 - val_accuracy: 0.9443\n",
      "Epoch 56/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0955 - accuracy: 0.9456 - val_loss: 0.0937 - val_accuracy: 0.9446\n",
      "Epoch 57/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0947 - accuracy: 0.9449 - val_loss: 0.0957 - val_accuracy: 0.9443\n",
      "Epoch 58/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0938 - accuracy: 0.9451 - val_loss: 0.0941 - val_accuracy: 0.9439\n",
      "Epoch 59/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0945 - accuracy: 0.9449 - val_loss: 0.0941 - val_accuracy: 0.9445\n",
      "Epoch 60/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0937 - accuracy: 0.9453 - val_loss: 0.0944 - val_accuracy: 0.9446\n",
      "Epoch 61/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0957 - accuracy: 0.9450 - val_loss: 0.0940 - val_accuracy: 0.9429\n",
      "Epoch 62/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0946 - accuracy: 0.9452 - val_loss: 0.0945 - val_accuracy: 0.9443\n",
      "Epoch 63/100\n",
      "2497/2497 [==============================] - 10s 4ms/step - loss: 0.0937 - accuracy: 0.9455 - val_loss: 0.0950 - val_accuracy: 0.9435\n",
      "Epoch 64/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0946 - accuracy: 0.9453 - val_loss: 0.0941 - val_accuracy: 0.9442\n",
      "Epoch 65/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0950 - accuracy: 0.9458 - val_loss: 0.0937 - val_accuracy: 0.9444\n",
      "Epoch 66/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0939 - accuracy: 0.9453 - val_loss: 0.0947 - val_accuracy: 0.9439\n",
      "Epoch 67/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0939 - accuracy: 0.9458 - val_loss: 0.0955 - val_accuracy: 0.9448\n",
      "Epoch 68/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0942 - accuracy: 0.9452 - val_loss: 0.0943 - val_accuracy: 0.9433\n",
      "Epoch 69/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0958 - accuracy: 0.9452 - val_loss: 0.0940 - val_accuracy: 0.9434\n",
      "Epoch 70/100\n",
      "2497/2497 [==============================] - 10s 4ms/step - loss: 0.0934 - accuracy: 0.9457 - val_loss: 0.0991 - val_accuracy: 0.9427\n",
      "Epoch 71/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0944 - accuracy: 0.9450 - val_loss: 0.0951 - val_accuracy: 0.9431\n",
      "Epoch 72/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0975 - accuracy: 0.9443 - val_loss: 0.0941 - val_accuracy: 0.9440\n",
      "Epoch 73/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0945 - accuracy: 0.9457 - val_loss: 0.0947 - val_accuracy: 0.9449\n",
      "Epoch 74/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0940 - accuracy: 0.9454 - val_loss: 0.0945 - val_accuracy: 0.9445\n",
      "Epoch 75/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0934 - accuracy: 0.9456 - val_loss: 0.0947 - val_accuracy: 0.9446\n",
      "Epoch 76/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0937 - accuracy: 0.9454 - val_loss: 0.0936 - val_accuracy: 0.9440\n",
      "Epoch 77/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0939 - accuracy: 0.9457 - val_loss: 0.0944 - val_accuracy: 0.9440\n",
      "Epoch 78/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0940 - accuracy: 0.9455 - val_loss: 0.0945 - val_accuracy: 0.9445\n",
      "Epoch 79/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0944 - accuracy: 0.9451 - val_loss: 0.0942 - val_accuracy: 0.9439\n",
      "Epoch 80/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0991 - accuracy: 0.9450 - val_loss: 0.0940 - val_accuracy: 0.9439\n",
      "Epoch 81/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0938 - accuracy: 0.9453 - val_loss: 0.0968 - val_accuracy: 0.9444\n",
      "Epoch 82/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0985 - accuracy: 0.9451 - val_loss: 0.0943 - val_accuracy: 0.9445\n",
      "Epoch 83/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0933 - accuracy: 0.9461 - val_loss: 0.0937 - val_accuracy: 0.9445\n",
      "Epoch 84/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0935 - accuracy: 0.9457 - val_loss: 0.0944 - val_accuracy: 0.9437\n",
      "Epoch 85/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0971 - accuracy: 0.9452 - val_loss: 0.0942 - val_accuracy: 0.9451\n",
      "Epoch 86/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0933 - accuracy: 0.9454 - val_loss: 0.0941 - val_accuracy: 0.9436\n",
      "Epoch 87/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0935 - accuracy: 0.9455 - val_loss: 0.0946 - val_accuracy: 0.9445\n",
      "Epoch 88/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0949 - accuracy: 0.9455 - val_loss: 0.0943 - val_accuracy: 0.9448\n",
      "Epoch 89/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0939 - accuracy: 0.9453 - val_loss: 0.0940 - val_accuracy: 0.9447\n",
      "Epoch 90/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0935 - accuracy: 0.9458 - val_loss: 0.0992 - val_accuracy: 0.9438\n",
      "Epoch 91/100\n",
      "2497/2497 [==============================] - 10s 4ms/step - loss: 0.0963 - accuracy: 0.9456 - val_loss: 0.0973 - val_accuracy: 0.9439\n",
      "Epoch 92/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0938 - accuracy: 0.9456 - val_loss: 0.0952 - val_accuracy: 0.9444\n",
      "Epoch 93/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0945 - accuracy: 0.9451 - val_loss: 0.0942 - val_accuracy: 0.9443\n",
      "Epoch 94/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0943 - accuracy: 0.9455 - val_loss: 0.0949 - val_accuracy: 0.9430\n",
      "Epoch 95/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0941 - accuracy: 0.9456 - val_loss: 0.0939 - val_accuracy: 0.9443\n",
      "Epoch 96/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0935 - accuracy: 0.9457 - val_loss: 0.0945 - val_accuracy: 0.9441\n",
      "Epoch 97/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0961 - accuracy: 0.9449 - val_loss: 0.0942 - val_accuracy: 0.9443\n",
      "Epoch 98/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0934 - accuracy: 0.9457 - val_loss: 0.0994 - val_accuracy: 0.9436\n",
      "Epoch 99/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0952 - accuracy: 0.9458 - val_loss: 0.0949 - val_accuracy: 0.9451\n",
      "Epoch 100/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0936 - accuracy: 0.9458 - val_loss: 0.0966 - val_accuracy: 0.9432\n",
      "Training Accuracy: 94.51%\n",
      "Testing Accuracy: 94.32%\n"
     ]
    }
   ],
   "source": [
    "# Determine input shape based on the number of features (7 input columns)\n",
    "input_shape = x_train.shape[1]\n",
    "\n",
    "# Determine number of classes for output layer\n",
    "num_classes = len(y_train.unique())  # Assuming y_train contains class labels\n",
    "\n",
    "# Create a Sequential model\n",
    "ANN_V10 = Sequential()\n",
    "\n",
    "# Add layers\n",
    "ANN_V10.add(Dense(128, input_shape=(input_shape,), activation='relu'))\n",
    "ANN_V10.add(Dense(64, activation='relu'))\n",
    "ANN_V10.add(Dense(32, activation='relu'))\n",
    "ANN_V10.add(Dense(num_classes, activation='softmax'))  # Softmax for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "ANN_V10.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "hist_ANN = ANN_V10.fit(x_train, y_train, epochs=100, batch_size=32,validation_data=(x_test, y_test))\n",
    "# Get training accuracy\n",
    "train_loss, train_accuracy = ANN_V10.evaluate(x_train, y_train, verbose=0)\n",
    "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Get testing accuracy\n",
    "test_loss, test_accuracy = ANN_V10.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Testing Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "86ddfcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_V10.save('ANN_V10.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9e0ae4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h = hist_ANN.history\n",
    "h.keys()\n",
    "plt.plot(h['accuracy'])\n",
    "plt.plot(h['val_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2e80cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist_ANN = pd.DataFrame(hist_ANN.history)\n",
    "df_hist_ANN.to_csv('df_hist_ANN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1748156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "ANN = load_model('ANN_V10.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "09908f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.45024726, -0.24726208, -0.77076946, -0.42244728,  1.29731963,\n",
       "       -0.9562663 , -1.66814771])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a197a43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 67ms/step\n",
      "['wheat']\n"
     ]
    }
   ],
   "source": [
    "new_data = np.array([[-0.45024726, -0.24726208, -0.77076946, -0.42244728,  1.29731963,\n",
    "       -0.9562663 , -1.66814771]])\n",
    "#new_data = new_data.reshape(new_data.shape[0], new_data.shape[1])\n",
    "prediction = ANN.predict(new_data)\n",
    "predicted_class = np.argmax(prediction, axis=-1)\n",
    "predicted_crop = encoder.inverse_transform(predicted_class)\n",
    "print(predicted_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d498280e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wheat'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.inverse_transform(y_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a823740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc4ce008",
   "metadata": {},
   "source": [
    "# CNN_V10 ----94.09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5c630d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import  train_test_split\n",
    "\n",
    "\n",
    "y=Y\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scale = StandardScaler()\n",
    "X_train = scale.fit_transform(X_train)\n",
    "X_test = scale.transform(X_test)\n",
    "\n",
    "# Reshape the input data for CNN\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8c197d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2497/2497 [==============================] - 12s 4ms/step - loss: 0.3573 - accuracy: 0.8914 - val_loss: 0.1461 - val_accuracy: 0.9321\n",
      "Epoch 2/100\n",
      "2497/2497 [==============================] - 10s 4ms/step - loss: 0.1432 - accuracy: 0.9296 - val_loss: 0.1336 - val_accuracy: 0.9323\n",
      "Epoch 3/100\n",
      "2497/2497 [==============================] - 10s 4ms/step - loss: 0.1360 - accuracy: 0.9322 - val_loss: 0.1386 - val_accuracy: 0.9324\n",
      "Epoch 4/100\n",
      "2497/2497 [==============================] - 10s 4ms/step - loss: 0.1285 - accuracy: 0.9344 - val_loss: 0.1269 - val_accuracy: 0.9317\n",
      "Epoch 5/100\n",
      "2497/2497 [==============================] - 10s 4ms/step - loss: 0.1245 - accuracy: 0.9358 - val_loss: 0.1298 - val_accuracy: 0.9345\n",
      "Epoch 6/100\n",
      "2497/2497 [==============================] - 10s 4ms/step - loss: 0.1228 - accuracy: 0.9357 - val_loss: 0.1196 - val_accuracy: 0.9358\n",
      "Epoch 7/100\n",
      "2497/2497 [==============================] - 10s 4ms/step - loss: 0.1191 - accuracy: 0.9374 - val_loss: 0.1161 - val_accuracy: 0.9376\n",
      "Epoch 8/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.1177 - accuracy: 0.9377 - val_loss: 0.1190 - val_accuracy: 0.9386\n",
      "Epoch 9/100\n",
      "2497/2497 [==============================] - 11s 4ms/step - loss: 0.1163 - accuracy: 0.9383 - val_loss: 0.1156 - val_accuracy: 0.9390\n",
      "Epoch 10/100\n",
      "2497/2497 [==============================] - 10s 4ms/step - loss: 0.1141 - accuracy: 0.9387 - val_loss: 0.1134 - val_accuracy: 0.9388\n",
      "Epoch 11/100\n",
      "2497/2497 [==============================] - 10s 4ms/step - loss: 0.1129 - accuracy: 0.9395 - val_loss: 0.1103 - val_accuracy: 0.9403\n",
      "Epoch 12/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.1115 - accuracy: 0.9388 - val_loss: 0.1096 - val_accuracy: 0.9410\n",
      "Epoch 13/100\n",
      "2497/2497 [==============================] - 10s 4ms/step - loss: 0.1101 - accuracy: 0.9397 - val_loss: 0.1082 - val_accuracy: 0.9401\n",
      "Epoch 14/100\n",
      "2497/2497 [==============================] - 10s 4ms/step - loss: 0.1092 - accuracy: 0.9409 - val_loss: 0.1084 - val_accuracy: 0.9404\n",
      "Epoch 15/100\n",
      "2497/2497 [==============================] - 10s 4ms/step - loss: 0.1079 - accuracy: 0.9408 - val_loss: 0.1063 - val_accuracy: 0.9407\n",
      "Epoch 16/100\n",
      "2497/2497 [==============================] - 10s 4ms/step - loss: 0.1074 - accuracy: 0.9402 - val_loss: 0.1070 - val_accuracy: 0.9407\n",
      "Epoch 17/100\n",
      "2497/2497 [==============================] - 10s 4ms/step - loss: 0.1064 - accuracy: 0.9409 - val_loss: 0.1079 - val_accuracy: 0.9400\n",
      "Epoch 18/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.1070 - accuracy: 0.9406 - val_loss: 0.1063 - val_accuracy: 0.9404\n",
      "Epoch 19/100\n",
      "2497/2497 [==============================] - 10s 4ms/step - loss: 0.1052 - accuracy: 0.9405 - val_loss: 0.1076 - val_accuracy: 0.9412\n",
      "Epoch 20/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.1054 - accuracy: 0.9410 - val_loss: 0.1028 - val_accuracy: 0.9414\n",
      "Epoch 21/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.1053 - accuracy: 0.9406 - val_loss: 0.1039 - val_accuracy: 0.9404\n",
      "Epoch 22/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.1038 - accuracy: 0.9406 - val_loss: 0.1034 - val_accuracy: 0.9402\n",
      "Epoch 23/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.1044 - accuracy: 0.9409 - val_loss: 0.1044 - val_accuracy: 0.9396\n",
      "Epoch 24/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.1032 - accuracy: 0.9417 - val_loss: 0.1018 - val_accuracy: 0.9409\n",
      "Epoch 25/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.1031 - accuracy: 0.9416 - val_loss: 0.1069 - val_accuracy: 0.9415\n",
      "Epoch 26/100\n",
      "2497/2497 [==============================] - 8s 3ms/step - loss: 0.1029 - accuracy: 0.9414 - val_loss: 0.1031 - val_accuracy: 0.9418\n",
      "Epoch 27/100\n",
      "2497/2497 [==============================] - 6s 3ms/step - loss: 0.1028 - accuracy: 0.9409 - val_loss: 0.1036 - val_accuracy: 0.9414\n",
      "Epoch 28/100\n",
      "2497/2497 [==============================] - 6s 2ms/step - loss: 0.1023 - accuracy: 0.9411 - val_loss: 0.1027 - val_accuracy: 0.9403\n",
      "Epoch 29/100\n",
      "2497/2497 [==============================] - 6s 2ms/step - loss: 0.1032 - accuracy: 0.9416 - val_loss: 0.1044 - val_accuracy: 0.9386\n",
      "Epoch 30/100\n",
      "2497/2497 [==============================] - 6s 2ms/step - loss: 0.1018 - accuracy: 0.9429 - val_loss: 0.1014 - val_accuracy: 0.9400\n",
      "Epoch 31/100\n",
      "2497/2497 [==============================] - 7s 3ms/step - loss: 0.1014 - accuracy: 0.9418 - val_loss: 0.1060 - val_accuracy: 0.9390\n",
      "Epoch 32/100\n",
      "2497/2497 [==============================] - 6s 2ms/step - loss: 0.1014 - accuracy: 0.9422 - val_loss: 0.1020 - val_accuracy: 0.9391\n",
      "Epoch 33/100\n",
      "2497/2497 [==============================] - 6s 2ms/step - loss: 0.1018 - accuracy: 0.9426 - val_loss: 0.0999 - val_accuracy: 0.9414\n",
      "Epoch 34/100\n",
      "2497/2497 [==============================] - 6s 3ms/step - loss: 0.1007 - accuracy: 0.9420 - val_loss: 0.0999 - val_accuracy: 0.9416\n",
      "Epoch 35/100\n",
      "2497/2497 [==============================] - 8s 3ms/step - loss: 0.1005 - accuracy: 0.9424 - val_loss: 0.1055 - val_accuracy: 0.9403\n",
      "Epoch 36/100\n",
      "2497/2497 [==============================] - 7s 3ms/step - loss: 0.1011 - accuracy: 0.9423 - val_loss: 0.1004 - val_accuracy: 0.9426\n",
      "Epoch 37/100\n",
      "2497/2497 [==============================] - 9s 3ms/step - loss: 0.1001 - accuracy: 0.9423 - val_loss: 0.1014 - val_accuracy: 0.9422\n",
      "Epoch 38/100\n",
      "2497/2497 [==============================] - 7s 3ms/step - loss: 0.1007 - accuracy: 0.9428 - val_loss: 0.1035 - val_accuracy: 0.9413\n",
      "Epoch 39/100\n",
      "2497/2497 [==============================] - 8s 3ms/step - loss: 0.1002 - accuracy: 0.9425 - val_loss: 0.0992 - val_accuracy: 0.9416\n",
      "Epoch 40/100\n",
      "2497/2497 [==============================] - 6s 2ms/step - loss: 0.0998 - accuracy: 0.9428 - val_loss: 0.0986 - val_accuracy: 0.9414\n",
      "Epoch 41/100\n",
      "2497/2497 [==============================] - 6s 2ms/step - loss: 0.1004 - accuracy: 0.9424 - val_loss: 0.0998 - val_accuracy: 0.9423\n",
      "Epoch 42/100\n",
      "2497/2497 [==============================] - 6s 2ms/step - loss: 0.0994 - accuracy: 0.9441 - val_loss: 0.1018 - val_accuracy: 0.9428\n",
      "Epoch 43/100\n",
      "2497/2497 [==============================] - 8s 3ms/step - loss: 0.0996 - accuracy: 0.9430 - val_loss: 0.1005 - val_accuracy: 0.9422\n",
      "Epoch 44/100\n",
      "2497/2497 [==============================] - 8s 3ms/step - loss: 0.0995 - accuracy: 0.9428 - val_loss: 0.1007 - val_accuracy: 0.9424\n",
      "Epoch 45/100\n",
      "2497/2497 [==============================] - 8s 3ms/step - loss: 0.0993 - accuracy: 0.9425 - val_loss: 0.1003 - val_accuracy: 0.9431\n",
      "Epoch 46/100\n",
      "2497/2497 [==============================] - 8s 3ms/step - loss: 0.0998 - accuracy: 0.9425 - val_loss: 0.1003 - val_accuracy: 0.9425\n",
      "Epoch 47/100\n",
      "2497/2497 [==============================] - 8s 3ms/step - loss: 0.0993 - accuracy: 0.9434 - val_loss: 0.1007 - val_accuracy: 0.9422\n",
      "Epoch 48/100\n",
      "2497/2497 [==============================] - 8s 3ms/step - loss: 0.0990 - accuracy: 0.9435 - val_loss: 0.0988 - val_accuracy: 0.9437\n",
      "Epoch 49/100\n",
      "2497/2497 [==============================] - 8s 3ms/step - loss: 0.0995 - accuracy: 0.9433 - val_loss: 0.1037 - val_accuracy: 0.9436\n",
      "Epoch 50/100\n",
      "2497/2497 [==============================] - 8s 3ms/step - loss: 0.0989 - accuracy: 0.9427 - val_loss: 0.1000 - val_accuracy: 0.9416\n",
      "Epoch 51/100\n",
      "2497/2497 [==============================] - 7s 3ms/step - loss: 0.0991 - accuracy: 0.9431 - val_loss: 0.0985 - val_accuracy: 0.9433\n",
      "Epoch 52/100\n",
      "2497/2497 [==============================] - 6s 2ms/step - loss: 0.0985 - accuracy: 0.9442 - val_loss: 0.0989 - val_accuracy: 0.9416\n",
      "Epoch 53/100\n",
      "2497/2497 [==============================] - 8s 3ms/step - loss: 0.0987 - accuracy: 0.9434 - val_loss: 0.0983 - val_accuracy: 0.9425\n",
      "Epoch 54/100\n",
      "2497/2497 [==============================] - 8s 3ms/step - loss: 0.0985 - accuracy: 0.9437 - val_loss: 0.0989 - val_accuracy: 0.9420\n",
      "Epoch 55/100\n",
      "2497/2497 [==============================] - 8s 3ms/step - loss: 0.0996 - accuracy: 0.9440 - val_loss: 0.0974 - val_accuracy: 0.9440\n",
      "Epoch 56/100\n",
      "2497/2497 [==============================] - 8s 3ms/step - loss: 0.0981 - accuracy: 0.9438 - val_loss: 0.0982 - val_accuracy: 0.9435\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2497/2497 [==============================] - 8s 3ms/step - loss: 0.0983 - accuracy: 0.9439 - val_loss: 0.0994 - val_accuracy: 0.9428\n",
      "Epoch 58/100\n",
      "2497/2497 [==============================] - 8s 3ms/step - loss: 0.0976 - accuracy: 0.9429 - val_loss: 0.0980 - val_accuracy: 0.9427\n",
      "Epoch 59/100\n",
      "2497/2497 [==============================] - 8s 3ms/step - loss: 0.0980 - accuracy: 0.9434 - val_loss: 0.0998 - val_accuracy: 0.9429\n",
      "Epoch 60/100\n",
      "2497/2497 [==============================] - 7s 3ms/step - loss: 0.0979 - accuracy: 0.9438 - val_loss: 0.0965 - val_accuracy: 0.9443\n",
      "Epoch 61/100\n",
      "2497/2497 [==============================] - 8s 3ms/step - loss: 0.0995 - accuracy: 0.9431 - val_loss: 0.0970 - val_accuracy: 0.9433\n",
      "Epoch 62/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0980 - accuracy: 0.9439 - val_loss: 0.1001 - val_accuracy: 0.9437\n",
      "Epoch 63/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0984 - accuracy: 0.9437 - val_loss: 0.0967 - val_accuracy: 0.9428\n",
      "Epoch 64/100\n",
      "2497/2497 [==============================] - 9s 3ms/step - loss: 0.0975 - accuracy: 0.9432 - val_loss: 0.0983 - val_accuracy: 0.9436\n",
      "Epoch 65/100\n",
      "2497/2497 [==============================] - 9s 3ms/step - loss: 0.0975 - accuracy: 0.9438 - val_loss: 0.1005 - val_accuracy: 0.9424\n",
      "Epoch 66/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0987 - accuracy: 0.9434 - val_loss: 0.0984 - val_accuracy: 0.9424\n",
      "Epoch 67/100\n",
      "2497/2497 [==============================] - 6s 2ms/step - loss: 0.0976 - accuracy: 0.9438 - val_loss: 0.0979 - val_accuracy: 0.9426\n",
      "Epoch 68/100\n",
      "2497/2497 [==============================] - 7s 3ms/step - loss: 0.0970 - accuracy: 0.9446 - val_loss: 0.0972 - val_accuracy: 0.9436\n",
      "Epoch 69/100\n",
      "2497/2497 [==============================] - 7s 3ms/step - loss: 0.0989 - accuracy: 0.9441 - val_loss: 0.0988 - val_accuracy: 0.9424\n",
      "Epoch 70/100\n",
      "2497/2497 [==============================] - 8s 3ms/step - loss: 0.0974 - accuracy: 0.9442 - val_loss: 0.0959 - val_accuracy: 0.9428\n",
      "Epoch 71/100\n",
      "2497/2497 [==============================] - 8s 3ms/step - loss: 0.0972 - accuracy: 0.9437 - val_loss: 0.0961 - val_accuracy: 0.9448\n",
      "Epoch 72/100\n",
      "2497/2497 [==============================] - 8s 3ms/step - loss: 0.0974 - accuracy: 0.9440 - val_loss: 0.0980 - val_accuracy: 0.9425\n",
      "Epoch 73/100\n",
      "2497/2497 [==============================] - 9s 3ms/step - loss: 0.0973 - accuracy: 0.9444 - val_loss: 0.0971 - val_accuracy: 0.9426\n",
      "Epoch 74/100\n",
      "2497/2497 [==============================] - 8s 3ms/step - loss: 0.0977 - accuracy: 0.9436 - val_loss: 0.1013 - val_accuracy: 0.9416\n",
      "Epoch 75/100\n",
      "2497/2497 [==============================] - 9s 3ms/step - loss: 0.0970 - accuracy: 0.9438 - val_loss: 0.0984 - val_accuracy: 0.9436\n",
      "Epoch 76/100\n",
      "2497/2497 [==============================] - 9s 3ms/step - loss: 0.0976 - accuracy: 0.9436 - val_loss: 0.0996 - val_accuracy: 0.9410\n",
      "Epoch 77/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0970 - accuracy: 0.9442 - val_loss: 0.1035 - val_accuracy: 0.9410\n",
      "Epoch 78/100\n",
      "2497/2497 [==============================] - 9s 3ms/step - loss: 0.0968 - accuracy: 0.9440 - val_loss: 0.0965 - val_accuracy: 0.9440\n",
      "Epoch 79/100\n",
      "2497/2497 [==============================] - 8s 3ms/step - loss: 0.0971 - accuracy: 0.9439 - val_loss: 0.0975 - val_accuracy: 0.9413\n",
      "Epoch 80/100\n",
      "2497/2497 [==============================] - 9s 3ms/step - loss: 0.0970 - accuracy: 0.9444 - val_loss: 0.0966 - val_accuracy: 0.9431\n",
      "Epoch 81/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0967 - accuracy: 0.9440 - val_loss: 0.0974 - val_accuracy: 0.9421\n",
      "Epoch 82/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0970 - accuracy: 0.9443 - val_loss: 0.0975 - val_accuracy: 0.9440\n",
      "Epoch 83/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0969 - accuracy: 0.9442 - val_loss: 0.0964 - val_accuracy: 0.9438\n",
      "Epoch 84/100\n",
      "2497/2497 [==============================] - 9s 3ms/step - loss: 0.0968 - accuracy: 0.9443 - val_loss: 0.0983 - val_accuracy: 0.9422\n",
      "Epoch 85/100\n",
      "2497/2497 [==============================] - 8s 3ms/step - loss: 0.0971 - accuracy: 0.9444 - val_loss: 0.0976 - val_accuracy: 0.9424\n",
      "Epoch 86/100\n",
      "2497/2497 [==============================] - 9s 3ms/step - loss: 0.0972 - accuracy: 0.9442 - val_loss: 0.0985 - val_accuracy: 0.9429\n",
      "Epoch 87/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0965 - accuracy: 0.9443 - val_loss: 0.0975 - val_accuracy: 0.9444\n",
      "Epoch 88/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0965 - accuracy: 0.9446 - val_loss: 0.1015 - val_accuracy: 0.9400\n",
      "Epoch 89/100\n",
      "2497/2497 [==============================] - 9s 4ms/step - loss: 0.0966 - accuracy: 0.9441 - val_loss: 0.0985 - val_accuracy: 0.9421\n",
      "Epoch 90/100\n",
      "2497/2497 [==============================] - 8s 3ms/step - loss: 0.0977 - accuracy: 0.9436 - val_loss: 0.0958 - val_accuracy: 0.9427\n",
      "Epoch 91/100\n",
      "2497/2497 [==============================] - 7s 3ms/step - loss: 0.0967 - accuracy: 0.9446 - val_loss: 0.0960 - val_accuracy: 0.9437\n",
      "Epoch 92/100\n",
      "2497/2497 [==============================] - 8s 3ms/step - loss: 0.0966 - accuracy: 0.9443 - val_loss: 0.0974 - val_accuracy: 0.9415\n",
      "Epoch 93/100\n",
      "2497/2497 [==============================] - 7s 3ms/step - loss: 0.0974 - accuracy: 0.9442 - val_loss: 0.0963 - val_accuracy: 0.9440\n",
      "Epoch 94/100\n",
      "2497/2497 [==============================] - 9s 3ms/step - loss: 0.0963 - accuracy: 0.9443 - val_loss: 0.0967 - val_accuracy: 0.9429\n",
      "Epoch 95/100\n",
      "2497/2497 [==============================] - 9s 3ms/step - loss: 0.0966 - accuracy: 0.9442 - val_loss: 0.0963 - val_accuracy: 0.9441\n",
      "Epoch 96/100\n",
      "2497/2497 [==============================] - 9s 3ms/step - loss: 0.0964 - accuracy: 0.9442 - val_loss: 0.0959 - val_accuracy: 0.9430\n",
      "Epoch 97/100\n",
      "2497/2497 [==============================] - 8s 3ms/step - loss: 0.0971 - accuracy: 0.9446 - val_loss: 0.0978 - val_accuracy: 0.9440\n",
      "Epoch 98/100\n",
      "2497/2497 [==============================] - 7s 3ms/step - loss: 0.0969 - accuracy: 0.9445 - val_loss: 0.0993 - val_accuracy: 0.9411\n",
      "Epoch 99/100\n",
      "2497/2497 [==============================] - 8s 3ms/step - loss: 0.0960 - accuracy: 0.9450 - val_loss: 0.0960 - val_accuracy: 0.9429\n",
      "Epoch 100/100\n",
      "2497/2497 [==============================] - 9s 3ms/step - loss: 0.0977 - accuracy: 0.9445 - val_loss: 0.0957 - val_accuracy: 0.9436\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0957 - accuracy: 0.9436\n",
      "Test Accuracy: 94.36%\n"
     ]
    }
   ],
   "source": [
    "CNN_V10 = Sequential()\n",
    "CNN_V10.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "CNN_V10.add(MaxPooling1D(pool_size=2))\n",
    "CNN_V10.add(Flatten())\n",
    "CNN_V10.add(Dense(128, activation='relu'))\n",
    "#model2.add(Dropout(0.3))\n",
    "CNN_V10.add(Dense(len(y.unique()), activation='softmax'))\n",
    "\n",
    "CNN_V10.compile(loss = 'sparse_categorical_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
    "CNN_V10.fit(X_train_reshaped,y_train,epochs = 100,batch_size = 32,validation_data = (X_test_reshaped,y_test))\n",
    "test_loss, test_accuracy = CNN_V10.evaluate(X_test_reshaped, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e81941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist_CNN = pd.DataFrame(hist_CNN.history)\n",
    "df_hist_CNN.to_csv(\"df_hist_CNN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61ba6b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 94.48%\n",
      "Testing Accuracy: 94.36%\n"
     ]
    }
   ],
   "source": [
    "# Get training accuracy\n",
    "train_loss, train_accuracy = CNN_V10.evaluate(X_train_reshaped,y_train, verbose=0)\n",
    "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Get testing accuracy\n",
    "test_loss, test_accuracy = CNN_V10.evaluate(X_test_reshaped,y_test, verbose=0)\n",
    "print(f\"Testing Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f5429b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_V10.save('CNN_V10.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3381f918",
   "metadata": {},
   "source": [
    "# loading and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a8f858d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 94.48%\n",
      "Testing Accuracy: 94.36%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "CNN = load_model('CNN_V10.keras')\n",
    "# Get training accuracy\n",
    "train_loss, train_accuracy = CNN.evaluate(X_train_reshaped,y_train, verbose=0)\n",
    "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Get testing accuracy\n",
    "test_loss, test_accuracy = CNN.evaluate(X_test_reshaped,y_test, verbose=0)\n",
    "print(f\"Testing Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b1f1167a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.45024726, -0.24726208, -0.77076946, -0.42244728,  1.29731963,\n",
       "       -0.9562663 , -1.66814771])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoder.inverse_transform(y_test)\n",
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9ac4eb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 89ms/step\n",
      "['wheat']\n"
     ]
    }
   ],
   "source": [
    "new_data = np.array([[-0.45024726, -0.24726208, -0.77076946, -0.42244728,  1.29731963,\n",
    "       -0.9562663 , -1.66814771]])\n",
    "new_data = new_data.reshape(new_data.shape[0], new_data.shape[1],1)\n",
    "prediction = CNN.predict(new_data)\n",
    "predicted_class = np.argmax(prediction, axis=-1)\n",
    "predicted_crop = encoder.inverse_transform(predicted_class)\n",
    "print(predicted_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "64768c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wheat'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.inverse_transform(y_test)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf70d956",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e36fb0a",
   "metadata": {},
   "source": [
    "# LSTM_V10-94.57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e03d3324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>pH</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.500466</td>\n",
       "      <td>-0.106574</td>\n",
       "      <td>-0.774068</td>\n",
       "      <td>-1.511053</td>\n",
       "      <td>-0.947562</td>\n",
       "      <td>-1.211062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.259146</td>\n",
       "      <td>-0.106574</td>\n",
       "      <td>-0.070827</td>\n",
       "      <td>-0.482635</td>\n",
       "      <td>0.772190</td>\n",
       "      <td>0.340009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.260078</td>\n",
       "      <td>-0.106574</td>\n",
       "      <td>-0.774068</td>\n",
       "      <td>0.031574</td>\n",
       "      <td>0.745846</td>\n",
       "      <td>0.278240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.259146</td>\n",
       "      <td>-0.106574</td>\n",
       "      <td>-0.070827</td>\n",
       "      <td>-0.284862</td>\n",
       "      <td>-0.898531</td>\n",
       "      <td>-0.174727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.500466</td>\n",
       "      <td>-0.106574</td>\n",
       "      <td>-0.774068</td>\n",
       "      <td>-1.115508</td>\n",
       "      <td>-0.881867</td>\n",
       "      <td>-0.642794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79874</th>\n",
       "      <td>0.259146</td>\n",
       "      <td>-0.106574</td>\n",
       "      <td>-0.070827</td>\n",
       "      <td>-0.403526</td>\n",
       "      <td>-0.334961</td>\n",
       "      <td>-0.339443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79875</th>\n",
       "      <td>1.271962</td>\n",
       "      <td>-0.106574</td>\n",
       "      <td>-0.774068</td>\n",
       "      <td>-0.601298</td>\n",
       "      <td>-0.153596</td>\n",
       "      <td>-0.064917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79876</th>\n",
       "      <td>-1.260078</td>\n",
       "      <td>-0.106574</td>\n",
       "      <td>-0.774068</td>\n",
       "      <td>0.071129</td>\n",
       "      <td>0.304812</td>\n",
       "      <td>0.200250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79877</th>\n",
       "      <td>1.271962</td>\n",
       "      <td>1.221818</td>\n",
       "      <td>0.808224</td>\n",
       "      <td>0.901774</td>\n",
       "      <td>-0.681771</td>\n",
       "      <td>-0.251594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79878</th>\n",
       "      <td>0.259146</td>\n",
       "      <td>-0.106574</td>\n",
       "      <td>-0.070827</td>\n",
       "      <td>-0.205753</td>\n",
       "      <td>-1.014548</td>\n",
       "      <td>-0.736270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79879 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              N         P         K        pH  rainfall  temperature\n",
       "0     -0.500466 -0.106574 -0.774068 -1.511053 -0.947562    -1.211062\n",
       "1      0.259146 -0.106574 -0.070827 -0.482635  0.772190     0.340009\n",
       "2     -1.260078 -0.106574 -0.774068  0.031574  0.745846     0.278240\n",
       "3      0.259146 -0.106574 -0.070827 -0.284862 -0.898531    -0.174727\n",
       "4     -0.500466 -0.106574 -0.774068 -1.115508 -0.881867    -0.642794\n",
       "...         ...       ...       ...       ...       ...          ...\n",
       "79874  0.259146 -0.106574 -0.070827 -0.403526 -0.334961    -0.339443\n",
       "79875  1.271962 -0.106574 -0.774068 -0.601298 -0.153596    -0.064917\n",
       "79876 -1.260078 -0.106574 -0.774068  0.071129  0.304812     0.200250\n",
       "79877  1.271962  1.221818  0.808224  0.901774 -0.681771    -0.251594\n",
       "79878  0.259146 -0.106574 -0.070827 -0.205753 -1.014548    -0.736270\n",
       "\n",
       "[79879 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_columns = ['State_Name','N', 'P', 'K', 'pH', 'rainfall', 'temperature']\n",
    "\n",
    "x_train_df = pd.DataFrame(x_train,columns = x_columns)\n",
    "x_test_df = pd.DataFrame(x_test,columns = x_columns)\n",
    "x_train_df = x_train_df.drop('State_Name',axis= 1)\n",
    "x_test_df= x_test_df.drop('State_Name',axis= 1)\n",
    "x_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cdeaadd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAMU GOPI\\AppData\\Local\\Temp\\ipykernel_15380\\2702284416.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['State_Name'] = state_encoder.fit_transform(data['State_Name'])\n",
      "C:\\Users\\RAMU GOPI\\AppData\\Local\\Temp\\ipykernel_15380\\2702284416.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Crop'] = output_encoder.fit_transform(data['Crop'])\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "columns = ['State_Name', 'N', 'P', 'K', 'pH', 'rainfall', 'temperature', 'Crop']\n",
    "data = dataset[columns]\n",
    "\n",
    "# Encoding categorical columns\n",
    "state_encoder = LabelEncoder()\n",
    "data['State_Name'] = state_encoder.fit_transform(data['State_Name'])\n",
    "\n",
    "# Assuming 'Crop' is the output column, encode it\n",
    "output_encoder = LabelEncoder()\n",
    "data['Crop'] = output_encoder.fit_transform(data['Crop'])\n",
    "num_classes = len(output_encoder.classes_)\n",
    "\n",
    "# Split dataset into features (X) and labels (y)\n",
    "X = data.drop(columns=['Crop'])\n",
    "y = data['Crop']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "x_test = X_test\n",
    "scale = StandardScaler()\n",
    "X_train = scale.fit_transform(X_train)\n",
    "X_test = scale.transform(X_test)\n",
    "\n",
    "# Reshape the input data\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "# # Convert labels to categorical if not already\n",
    "# y_train_cat = to_categorical(y_train, num_classes=num_classes)\n",
    "# y_test_cat = to_categorical(y_test, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b68a9ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2497/2497 [==============================] - 34s 12ms/step - loss: 0.3306 - accuracy: 0.8964 - val_loss: 0.1369 - val_accuracy: 0.9332\n",
      "Epoch 2/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.1331 - accuracy: 0.9329 - val_loss: 0.1329 - val_accuracy: 0.9337\n",
      "Epoch 3/100\n",
      "2497/2497 [==============================] - 31s 13ms/step - loss: 0.1231 - accuracy: 0.9363 - val_loss: 0.1220 - val_accuracy: 0.9354\n",
      "Epoch 4/100\n",
      "2497/2497 [==============================] - 31s 12ms/step - loss: 0.1166 - accuracy: 0.9379 - val_loss: 0.1142 - val_accuracy: 0.9367\n",
      "Epoch 5/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.1121 - accuracy: 0.9400 - val_loss: 0.1086 - val_accuracy: 0.9404\n",
      "Epoch 6/100\n",
      "2497/2497 [==============================] - 29s 12ms/step - loss: 0.1072 - accuracy: 0.9407 - val_loss: 0.1031 - val_accuracy: 0.9425\n",
      "Epoch 7/100\n",
      "2497/2497 [==============================] - 31s 12ms/step - loss: 0.1047 - accuracy: 0.9419 - val_loss: 0.1035 - val_accuracy: 0.9413\n",
      "Epoch 8/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.1039 - accuracy: 0.9417 - val_loss: 0.1005 - val_accuracy: 0.9429\n",
      "Epoch 9/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.1019 - accuracy: 0.9422 - val_loss: 0.1002 - val_accuracy: 0.9432\n",
      "Epoch 10/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.1007 - accuracy: 0.9429 - val_loss: 0.1017 - val_accuracy: 0.9388\n",
      "Epoch 11/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.1008 - accuracy: 0.9427 - val_loss: 0.0985 - val_accuracy: 0.9432\n",
      "Epoch 12/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.1005 - accuracy: 0.9431 - val_loss: 0.0982 - val_accuracy: 0.9428\n",
      "Epoch 13/100\n",
      "2497/2497 [==============================] - 31s 12ms/step - loss: 0.0995 - accuracy: 0.9436 - val_loss: 0.0994 - val_accuracy: 0.9414\n",
      "Epoch 14/100\n",
      "2497/2497 [==============================] - 29s 12ms/step - loss: 0.0995 - accuracy: 0.9432 - val_loss: 0.0974 - val_accuracy: 0.9447\n",
      "Epoch 15/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0984 - accuracy: 0.9439 - val_loss: 0.0978 - val_accuracy: 0.9438\n",
      "Epoch 16/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0989 - accuracy: 0.9438 - val_loss: 0.1000 - val_accuracy: 0.9421\n",
      "Epoch 17/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0988 - accuracy: 0.9430 - val_loss: 0.0968 - val_accuracy: 0.9429\n",
      "Epoch 18/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0974 - accuracy: 0.9434 - val_loss: 0.0960 - val_accuracy: 0.9439\n",
      "Epoch 19/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0979 - accuracy: 0.9441 - val_loss: 0.0977 - val_accuracy: 0.9425\n",
      "Epoch 20/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0972 - accuracy: 0.9438 - val_loss: 0.0981 - val_accuracy: 0.9427\n",
      "Epoch 21/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0980 - accuracy: 0.9436 - val_loss: 0.0966 - val_accuracy: 0.9438\n",
      "Epoch 22/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0975 - accuracy: 0.9441 - val_loss: 0.0964 - val_accuracy: 0.9442\n",
      "Epoch 23/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0965 - accuracy: 0.9437 - val_loss: 0.0969 - val_accuracy: 0.9420\n",
      "Epoch 24/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0970 - accuracy: 0.9440 - val_loss: 0.1339 - val_accuracy: 0.9360\n",
      "Epoch 25/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0965 - accuracy: 0.9437 - val_loss: 0.0976 - val_accuracy: 0.9426\n",
      "Epoch 26/100\n",
      "2497/2497 [==============================] - 31s 12ms/step - loss: 0.0962 - accuracy: 0.9441 - val_loss: 0.0948 - val_accuracy: 0.9443\n",
      "Epoch 27/100\n",
      "2497/2497 [==============================] - 31s 12ms/step - loss: 0.0979 - accuracy: 0.9440 - val_loss: 0.0965 - val_accuracy: 0.9429\n",
      "Epoch 28/100\n",
      "2497/2497 [==============================] - 31s 12ms/step - loss: 0.0958 - accuracy: 0.9448 - val_loss: 0.0953 - val_accuracy: 0.9443\n",
      "Epoch 29/100\n",
      "2497/2497 [==============================] - 31s 12ms/step - loss: 0.0961 - accuracy: 0.9442 - val_loss: 0.0960 - val_accuracy: 0.9436\n",
      "Epoch 30/100\n",
      "2497/2497 [==============================] - 31s 12ms/step - loss: 0.0955 - accuracy: 0.9443 - val_loss: 0.0952 - val_accuracy: 0.9445\n",
      "Epoch 31/100\n",
      "2497/2497 [==============================] - 31s 12ms/step - loss: 0.0965 - accuracy: 0.9439 - val_loss: 0.0953 - val_accuracy: 0.9437\n",
      "Epoch 32/100\n",
      "2497/2497 [==============================] - 31s 12ms/step - loss: 0.0951 - accuracy: 0.9448 - val_loss: 0.0942 - val_accuracy: 0.9445\n",
      "Epoch 33/100\n",
      "2497/2497 [==============================] - 31s 12ms/step - loss: 0.0958 - accuracy: 0.9446 - val_loss: 0.0965 - val_accuracy: 0.9433\n",
      "Epoch 34/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0950 - accuracy: 0.9443 - val_loss: 0.0954 - val_accuracy: 0.9434\n",
      "Epoch 35/100\n",
      "2497/2497 [==============================] - 28s 11ms/step - loss: 0.0949 - accuracy: 0.9449 - val_loss: 0.0952 - val_accuracy: 0.9430\n",
      "Epoch 36/100\n",
      "2497/2497 [==============================] - 29s 12ms/step - loss: 0.0960 - accuracy: 0.9443 - val_loss: 0.0946 - val_accuracy: 0.9446\n",
      "Epoch 37/100\n",
      "2497/2497 [==============================] - 29s 12ms/step - loss: 0.0947 - accuracy: 0.9449 - val_loss: 0.0948 - val_accuracy: 0.9442\n",
      "Epoch 38/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0948 - accuracy: 0.9448 - val_loss: 0.0951 - val_accuracy: 0.9434\n",
      "Epoch 39/100\n",
      "2497/2497 [==============================] - 29s 12ms/step - loss: 0.0947 - accuracy: 0.9445 - val_loss: 0.0964 - val_accuracy: 0.9447\n",
      "Epoch 40/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0955 - accuracy: 0.9450 - val_loss: 0.0952 - val_accuracy: 0.9450\n",
      "Epoch 41/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0954 - accuracy: 0.9447 - val_loss: 0.0944 - val_accuracy: 0.9453\n",
      "Epoch 42/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0944 - accuracy: 0.9449 - val_loss: 0.0952 - val_accuracy: 0.9437\n",
      "Epoch 43/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0945 - accuracy: 0.9451 - val_loss: 0.0944 - val_accuracy: 0.9443\n",
      "Epoch 44/100\n",
      "2497/2497 [==============================] - 29s 12ms/step - loss: 0.0946 - accuracy: 0.9454 - val_loss: 0.0945 - val_accuracy: 0.9446\n",
      "Epoch 45/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0954 - accuracy: 0.9452 - val_loss: 0.0970 - val_accuracy: 0.9446\n",
      "Epoch 46/100\n",
      "2497/2497 [==============================] - 29s 12ms/step - loss: 0.0944 - accuracy: 0.9450 - val_loss: 0.0945 - val_accuracy: 0.9441\n",
      "Epoch 47/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0980 - accuracy: 0.9450 - val_loss: 0.0941 - val_accuracy: 0.9442\n",
      "Epoch 48/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0940 - accuracy: 0.9447 - val_loss: 0.0942 - val_accuracy: 0.9443\n",
      "Epoch 49/100\n",
      "2497/2497 [==============================] - 29s 12ms/step - loss: 0.0944 - accuracy: 0.9452 - val_loss: 0.0945 - val_accuracy: 0.9437\n",
      "Epoch 50/100\n",
      "2497/2497 [==============================] - 31s 12ms/step - loss: 0.0943 - accuracy: 0.9457 - val_loss: 0.0944 - val_accuracy: 0.9438\n",
      "Epoch 51/100\n",
      "2497/2497 [==============================] - 31s 12ms/step - loss: 0.0940 - accuracy: 0.9453 - val_loss: 0.0944 - val_accuracy: 0.9434\n",
      "Epoch 52/100\n",
      "2497/2497 [==============================] - 31s 12ms/step - loss: 0.0945 - accuracy: 0.9454 - val_loss: 0.1257 - val_accuracy: 0.9404\n",
      "Epoch 53/100\n",
      "2497/2497 [==============================] - 32s 13ms/step - loss: 0.0942 - accuracy: 0.9454 - val_loss: 0.0939 - val_accuracy: 0.9448\n",
      "Epoch 54/100\n",
      "2497/2497 [==============================] - 31s 12ms/step - loss: 0.0939 - accuracy: 0.9455 - val_loss: 0.0940 - val_accuracy: 0.9447\n",
      "Epoch 55/100\n",
      "2497/2497 [==============================] - 31s 12ms/step - loss: 0.0942 - accuracy: 0.9454 - val_loss: 0.0945 - val_accuracy: 0.9433\n",
      "Epoch 56/100\n",
      "2497/2497 [==============================] - 31s 12ms/step - loss: 0.0942 - accuracy: 0.9458 - val_loss: 0.0943 - val_accuracy: 0.9443\n",
      "Epoch 57/100\n",
      "2497/2497 [==============================] - 31s 12ms/step - loss: 0.0938 - accuracy: 0.9455 - val_loss: 0.0965 - val_accuracy: 0.9440\n",
      "Epoch 58/100\n",
      "2497/2497 [==============================] - 31s 12ms/step - loss: 0.0944 - accuracy: 0.9453 - val_loss: 0.1026 - val_accuracy: 0.9431\n",
      "Epoch 59/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0953 - accuracy: 0.9453 - val_loss: 0.0943 - val_accuracy: 0.9438\n",
      "Epoch 60/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0941 - accuracy: 0.9455 - val_loss: 0.0942 - val_accuracy: 0.9442\n",
      "Epoch 61/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0936 - accuracy: 0.9460 - val_loss: 0.0942 - val_accuracy: 0.9446\n",
      "Epoch 62/100\n",
      "2497/2497 [==============================] - 29s 12ms/step - loss: 0.0939 - accuracy: 0.9453 - val_loss: 0.0936 - val_accuracy: 0.9441\n",
      "Epoch 63/100\n",
      "2497/2497 [==============================] - 29s 12ms/step - loss: 0.0942 - accuracy: 0.9456 - val_loss: 0.0946 - val_accuracy: 0.9444\n",
      "Epoch 64/100\n",
      "2497/2497 [==============================] - 31s 12ms/step - loss: 0.0938 - accuracy: 0.9457 - val_loss: 0.0937 - val_accuracy: 0.9457\n",
      "Epoch 65/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0955 - accuracy: 0.9456 - val_loss: 0.0941 - val_accuracy: 0.9440\n",
      "Epoch 66/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0935 - accuracy: 0.9455 - val_loss: 0.0947 - val_accuracy: 0.9448\n",
      "Epoch 67/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0947 - accuracy: 0.9460 - val_loss: 0.0939 - val_accuracy: 0.9443\n",
      "Epoch 68/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0936 - accuracy: 0.9453 - val_loss: 0.0937 - val_accuracy: 0.9443\n",
      "Epoch 69/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0939 - accuracy: 0.9459 - val_loss: 0.0940 - val_accuracy: 0.9424\n",
      "Epoch 70/100\n",
      "2497/2497 [==============================] - 29s 12ms/step - loss: 0.0937 - accuracy: 0.9452 - val_loss: 0.0938 - val_accuracy: 0.9452\n",
      "Epoch 71/100\n",
      "2497/2497 [==============================] - 29s 11ms/step - loss: 0.0943 - accuracy: 0.9452 - val_loss: 0.0939 - val_accuracy: 0.9451\n",
      "Epoch 72/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0935 - accuracy: 0.9459 - val_loss: 0.0938 - val_accuracy: 0.9443\n",
      "Epoch 73/100\n",
      "2497/2497 [==============================] - 29s 12ms/step - loss: 0.0940 - accuracy: 0.9451 - val_loss: 0.0941 - val_accuracy: 0.9441\n",
      "Epoch 74/100\n",
      "2497/2497 [==============================] - 29s 12ms/step - loss: 0.0955 - accuracy: 0.9454 - val_loss: 0.0949 - val_accuracy: 0.9442\n",
      "Epoch 75/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0934 - accuracy: 0.9460 - val_loss: 0.0940 - val_accuracy: 0.9449\n",
      "Epoch 76/100\n",
      "2497/2497 [==============================] - 29s 12ms/step - loss: 0.0937 - accuracy: 0.9457 - val_loss: 0.0942 - val_accuracy: 0.9446\n",
      "Epoch 77/100\n",
      "2497/2497 [==============================] - 29s 12ms/step - loss: 0.0947 - accuracy: 0.9454 - val_loss: 0.0943 - val_accuracy: 0.9445\n",
      "Epoch 78/100\n",
      "2497/2497 [==============================] - 29s 12ms/step - loss: 0.0938 - accuracy: 0.9456 - val_loss: 0.0943 - val_accuracy: 0.9447\n",
      "Epoch 79/100\n",
      "2497/2497 [==============================] - 29s 11ms/step - loss: 0.0940 - accuracy: 0.9462 - val_loss: 0.0945 - val_accuracy: 0.9442\n",
      "Epoch 80/100\n",
      "2497/2497 [==============================] - 29s 12ms/step - loss: 0.0936 - accuracy: 0.9456 - val_loss: 0.0940 - val_accuracy: 0.9439\n",
      "Epoch 81/100\n",
      "2497/2497 [==============================] - 29s 12ms/step - loss: 0.0938 - accuracy: 0.9455 - val_loss: 0.0940 - val_accuracy: 0.9450\n",
      "Epoch 82/100\n",
      "2497/2497 [==============================] - 29s 12ms/step - loss: 0.0941 - accuracy: 0.9455 - val_loss: 0.0948 - val_accuracy: 0.9433\n",
      "Epoch 83/100\n",
      "2497/2497 [==============================] - 29s 11ms/step - loss: 0.0933 - accuracy: 0.9457 - val_loss: 0.0941 - val_accuracy: 0.9443\n",
      "Epoch 84/100\n",
      "2497/2497 [==============================] - 29s 12ms/step - loss: 0.0935 - accuracy: 0.9459 - val_loss: 0.0940 - val_accuracy: 0.9451\n",
      "Epoch 85/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0935 - accuracy: 0.9457 - val_loss: 0.0936 - val_accuracy: 0.9448\n",
      "Epoch 86/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0936 - accuracy: 0.9455 - val_loss: 0.0942 - val_accuracy: 0.9454\n",
      "Epoch 87/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0956 - accuracy: 0.9453 - val_loss: 0.0942 - val_accuracy: 0.9452\n",
      "Epoch 88/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0936 - accuracy: 0.9459 - val_loss: 0.0946 - val_accuracy: 0.9434\n",
      "Epoch 89/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0936 - accuracy: 0.9458 - val_loss: 0.0947 - val_accuracy: 0.9448\n",
      "Epoch 90/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0937 - accuracy: 0.9461 - val_loss: 0.0958 - val_accuracy: 0.9445\n",
      "Epoch 91/100\n",
      "2497/2497 [==============================] - 29s 12ms/step - loss: 0.0937 - accuracy: 0.9455 - val_loss: 0.0943 - val_accuracy: 0.9437\n",
      "Epoch 92/100\n",
      "2497/2497 [==============================] - 29s 12ms/step - loss: 0.0948 - accuracy: 0.9451 - val_loss: 0.0991 - val_accuracy: 0.9434\n",
      "Epoch 93/100\n",
      "2497/2497 [==============================] - 29s 12ms/step - loss: 0.0935 - accuracy: 0.9458 - val_loss: 0.0937 - val_accuracy: 0.9448\n",
      "Epoch 94/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0934 - accuracy: 0.9462 - val_loss: 0.0947 - val_accuracy: 0.9449\n",
      "Epoch 95/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0936 - accuracy: 0.9452 - val_loss: 0.0938 - val_accuracy: 0.9448\n",
      "Epoch 96/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0936 - accuracy: 0.9452 - val_loss: 0.0941 - val_accuracy: 0.9447\n",
      "Epoch 97/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0935 - accuracy: 0.9459 - val_loss: 0.0945 - val_accuracy: 0.9444\n",
      "Epoch 98/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0942 - accuracy: 0.9456 - val_loss: 0.0967 - val_accuracy: 0.9447\n",
      "Epoch 99/100\n",
      "2497/2497 [==============================] - 30s 12ms/step - loss: 0.0961 - accuracy: 0.9458 - val_loss: 0.0946 - val_accuracy: 0.9435\n",
      "Epoch 100/100\n",
      "2497/2497 [==============================] - 29s 12ms/step - loss: 0.0932 - accuracy: 0.9461 - val_loss: 0.0940 - val_accuracy: 0.9436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d0bad529d0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout,LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# Define the model\n",
    "LSTM_V11 = Sequential()\n",
    "LSTM_V11.add(LSTM(256, input_shape=(1, X_train_reshaped.shape[2]), activation='relu'))\n",
    "#LSTM_V11.add(Dense(128,activation = 'relu'))\n",
    "LSTM_V11.add(Dense(num_classes, activation='softmax'))  # Adjust output units and activation for multiclass\n",
    "\n",
    "# Compile the model\n",
    "LSTM_V11.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "LSTM_V11.fit(X_train_reshaped, y_train, epochs=100, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# # Predict the crop\n",
    "# new_data = np.array([[0.5, 0.3, 0.2, 25, 60, 6.5, 100]])\n",
    "# new_data = new_data.reshape(new_data.shape[0], 1, new_data.shape[1])\n",
    "# prediction = LSTM_V10.predict(new_data)\n",
    "# predicted_class = np.argmax(prediction, axis=-1)\n",
    "# predicted_crop = output_encoder.inverse_transform(predicted_class)\n",
    "# print(predicted_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dd6a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f323c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_V11.save('LSTM_V11.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d69bd582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2497/2497 [==============================] - 9s 3ms/step - loss: 0.0960 - accuracy: 0.9455\n",
      "Training Accuracy: 94.55%\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.0938 - accuracy: 0.9462\n",
      "Testing Accuracy: 94.62%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "LSTM = load_model('LSTM_V11.keras')\n",
    "# Get training accuracy\n",
    "train_loss, train_accuracy = LSTM.evaluate(X_train_reshaped,y_train, verbose=1)\n",
    "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Get testing accuracy\n",
    "test_loss, test_accuracy = LSTM.evaluate(X_test_reshaped,y_test, verbose=1)\n",
    "print(f\"Testing Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f3c90edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.08362218,  0.00593459, -0.10503347,  0.63419203,  0.90616119,\n",
       "         0.39659741,  0.47473113]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_reshaped[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e2ff5bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 202ms/step\n",
      "['cashewnuts']\n"
     ]
    }
   ],
   "source": [
    "new_data = np.array([[ 1.08362218,  0.00593459, -0.10503347,  0.63419203,  0.90616119,\n",
    "         0.39659741,  0.47473113]])\n",
    "new_data = new_data.reshape(new_data.shape[0], 1,new_data.shape[1])\n",
    "prediction = LSTM.predict(new_data)\n",
    "predicted_class = np.argmax(prediction, axis=-1)\n",
    "predicted_crop = encoder.inverse_transform(predicted_class)\n",
    "print(predicted_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "110d386b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cashewnuts'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.inverse_transform(y_test)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9b6713",
   "metadata": {},
   "source": [
    "# GRU_V10-94.69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "17949503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAMU GOPI\\anaconda3\\Lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[148], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m GRU_V10\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m53\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     26\u001b[0m GRU_V10\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39mAdam(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.03\u001b[39m), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 27\u001b[0m GRU_V10\u001b[38;5;241m.\u001b[39mfit(X_train_reshaped, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test_reshaped, y_test))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:959\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    955\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    956\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;66;03m# no_variable_creation function.\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    961\u001b[0m   _, _, filtered_flat_args \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    962\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn\u001b[38;5;241m.\u001b[39m_function_spec  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    963\u001b[0m       \u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(\n\u001b[0;32m    964\u001b[0m           args, kwds))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:142\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m--> 142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[0;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mconcrete_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:396\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    393\u001b[0m   args \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39margs\n\u001b[0;32m    394\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[1;32m--> 396\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_concrete_function(\n\u001b[0;32m    397\u001b[0m     args, kwargs, func_graph)\n\u001b[0;32m    399\u001b[0m \u001b[38;5;66;03m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[0;32m    400\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39m_function_captures  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:300\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[1;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    297\u001b[0m   arg_names \u001b[38;5;241m=\u001b[39m base_arg_names\n\u001b[0;32m    299\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m monomorphic_function\u001b[38;5;241m.\u001b[39mConcreteFunction(\n\u001b[1;32m--> 300\u001b[0m     func_graph_module\u001b[38;5;241m.\u001b[39mfunc_graph_from_py_func(\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name,\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_function,\n\u001b[0;32m    303\u001b[0m         args,\n\u001b[0;32m    304\u001b[0m         kwargs,\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    306\u001b[0m         func_graph\u001b[38;5;241m=\u001b[39mfunc_graph,\n\u001b[0;32m    307\u001b[0m         autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autograph,\n\u001b[0;32m    308\u001b[0m         autograph_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autograph_options,\n\u001b[0;32m    309\u001b[0m         arg_names\u001b[38;5;241m=\u001b[39marg_names,\n\u001b[0;32m    310\u001b[0m         capture_by_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_capture_by_value,\n\u001b[0;32m    311\u001b[0m         create_placeholders\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m    313\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m    318\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1214\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1212\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1214\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1218\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:667\u001b[0m, in \u001b[0;36mFunction._compiler_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    664\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    665\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    666\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 667\u001b[0m     out \u001b[38;5;241m=\u001b[39m weak_wrapped_fn()\u001b[38;5;241m.\u001b[39m__wrapped__(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    668\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1189\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1189\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m autograph\u001b[38;5;241m.\u001b[39mconverted_call(\n\u001b[0;32m   1190\u001b[0m       original_func,\n\u001b[0;32m   1191\u001b[0m       args,\n\u001b[0;32m   1192\u001b[0m       kwargs,\n\u001b[0;32m   1193\u001b[0m       options\u001b[38;5;241m=\u001b[39mautograph\u001b[38;5;241m.\u001b[39mConversionOptions(\n\u001b[0;32m   1194\u001b[0m           recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1195\u001b[0m           optional_features\u001b[38;5;241m=\u001b[39mautograph_options,\n\u001b[0;32m   1196\u001b[0m           user_requested\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1197\u001b[0m       ))\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1199\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[1;32mC:\\Users\\RAMUGO~1\\AppData\\Local\\Temp\\__autograph_generated_fileqyjib7xi.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[0;32m    330\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: from cache\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[1;32m--> 331\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m ag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED:\n\u001b[0;32m    334\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph is disabled in context\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\engine\\training.py:1268\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1264\u001b[0m     run_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[0;32m   1265\u001b[0m         run_step, jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reduce_retracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1266\u001b[0m     )\n\u001b[0;32m   1267\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1268\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdistribute_strategy\u001b[38;5;241m.\u001b[39mrun(run_step, args\u001b[38;5;241m=\u001b[39m(data,))\n\u001b[0;32m   1269\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1270\u001b[0m     outputs,\n\u001b[0;32m   1271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[0;32m   1272\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_reduction_method,\n\u001b[0;32m   1273\u001b[0m )\n\u001b[0;32m   1274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1316\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m   1312\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1314\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[0;32m   1315\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 1316\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extended\u001b[38;5;241m.\u001b[39mcall_for_each_replica(fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2895\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2893\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   2894\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m-> 2895\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3696\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3694\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   3695\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m-> 3696\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\engine\\training.py:1249\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1249\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrain_step(data)\n\u001b[0;32m   1250\u001b[0m     \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\engine\\training.py:1054\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;66;03m# Run backwards pass.\u001b[39;00m\n\u001b[1;32m-> 1054\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mminimize(loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable_variables, tape\u001b[38;5;241m=\u001b[39mtape)\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\optimizers\\legacy\\optimizer_v2.py:585\u001b[0m, in \u001b[0;36mOptimizerV2.minimize\u001b[1;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mminimize\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss, var_list, grad_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    555\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \n\u001b[0;32m    557\u001b[0m \u001b[38;5;124;03m    This method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    583\u001b[0m \n\u001b[0;32m    584\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 585\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_gradients(\n\u001b[0;32m    586\u001b[0m         loss, var_list\u001b[38;5;241m=\u001b[39mvar_list, grad_loss\u001b[38;5;241m=\u001b[39mgrad_loss, tape\u001b[38;5;241m=\u001b[39mtape\n\u001b[0;32m    587\u001b[0m     )\n\u001b[0;32m    588\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_gradients(grads_and_vars, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\optimizers\\legacy\\optimizer_v2.py:643\u001b[0m, in \u001b[0;36mOptimizerV2._compute_gradients\u001b[1;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[0;32m    641\u001b[0m var_list \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(var_list)\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/gradients\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 643\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_gradients(\n\u001b[0;32m    644\u001b[0m         tape, loss, var_list, grad_loss\n\u001b[0;32m    645\u001b[0m     )\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assert_valid_dtypes(\n\u001b[0;32m    648\u001b[0m     [\n\u001b[0;32m    649\u001b[0m         v\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    652\u001b[0m     ]\n\u001b[0;32m    653\u001b[0m )\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grads_and_vars\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\optimizers\\legacy\\optimizer_v2.py:519\u001b[0m, in \u001b[0;36mOptimizerV2._get_gradients\u001b[1;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, tape, loss, var_list, grad_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    518\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 519\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, var_list, grad_loss)\n\u001b[0;32m    520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, var_list))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1063\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1057\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1058\u001b[0m       composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[0;32m   1059\u001b[0m           output_gradients))\n\u001b[0;32m   1060\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1061\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[1;32m-> 1063\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m imperative_grad\u001b[38;5;241m.\u001b[39mimperative_grad(\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape,\n\u001b[0;32m   1065\u001b[0m     flat_targets,\n\u001b[0;32m   1066\u001b[0m     flat_sources,\n\u001b[0;32m   1067\u001b[0m     output_gradients\u001b[38;5;241m=\u001b[39moutput_gradients,\n\u001b[0;32m   1068\u001b[0m     sources_raw\u001b[38;5;241m=\u001b[39mflat_sources_raw,\n\u001b[0;32m   1069\u001b[0m     unconnected_gradients\u001b[38;5;241m=\u001b[39munconnected_gradients)\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[0;32m   1072\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1073\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_TapeGradient(\n\u001b[0;32m     68\u001b[0m     tape\u001b[38;5;241m.\u001b[39m_tape,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     target,\n\u001b[0;32m     70\u001b[0m     sources,\n\u001b[0;32m     71\u001b[0m     output_gradients,\n\u001b[0;32m     72\u001b[0m     sources_raw,\n\u001b[0;32m     73\u001b[0m     compat\u001b[38;5;241m.\u001b[39mas_str(unconnected_gradients\u001b[38;5;241m.\u001b[39mvalue))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:146\u001b[0m, in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    144\u001b[0m     gradient_name_scope \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m forward_pass_name_scope \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:448\u001b[0m, in \u001b[0;36m_WhileGrad\u001b[1;34m(op, *grads)\u001b[0m\n\u001b[0;32m    445\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m counter \u001b[38;5;241m<\u001b[39m forward_loop_iters\n\u001b[0;32m    447\u001b[0m grad_cond_name \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39munique_grad_fn_name(op\u001b[38;5;241m.\u001b[39mget_attr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcond\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m--> 448\u001b[0m cond_grad_graph \u001b[38;5;241m=\u001b[39m func_graph_module\u001b[38;5;241m.\u001b[39mfunc_graph_from_py_func(\n\u001b[0;32m    449\u001b[0m     grad_cond_name, grad_cond, loop_vars, {},\n\u001b[0;32m    450\u001b[0m     func_graph\u001b[38;5;241m=\u001b[39mutil\u001b[38;5;241m.\u001b[39mWhileCondFuncGraph(grad_cond_name))\n\u001b[0;32m    452\u001b[0m _check_num_inputs_outputs(cond_grad_graph, body_grad_graph, \u001b[38;5;28mlen\u001b[39m(loop_vars))\n\u001b[0;32m    454\u001b[0m outputs \u001b[38;5;241m=\u001b[39m _build_while_op(\n\u001b[0;32m    455\u001b[0m     loop_vars,\n\u001b[0;32m    456\u001b[0m     cond_grad_graph,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    461\u001b[0m     num_original_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(body_grad_graph\u001b[38;5;241m.\u001b[39moutputs),\n\u001b[0;32m    462\u001b[0m     stateful_parallelism\u001b[38;5;241m=\u001b[39mstateful_parallelism)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1123\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1120\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m create_placeholders:\n\u001b[1;32m-> 1123\u001b[0m   func_args, func_kwargs \u001b[38;5;241m=\u001b[39m _create_placeholders(args, kwargs, arg_names)\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1125\u001b[0m   func_args, func_kwargs \u001b[38;5;241m=\u001b[39m args, kwargs\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1423\u001b[0m, in \u001b[0;36m_create_placeholders\u001b[1;34m(args, kwargs, arg_names)\u001b[0m\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, trace_type_arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(arg_names, arg_trace_types\u001b[38;5;241m.\u001b[39mcomponents):\n\u001b[0;32m   1422\u001b[0m   placeholder_context\u001b[38;5;241m.\u001b[39mupdate_naming_scope(name)\n\u001b[1;32m-> 1423\u001b[0m   placeholder \u001b[38;5;241m=\u001b[39m trace_type_arg\u001b[38;5;241m.\u001b[39mplaceholder_value(placeholder_context)\n\u001b[0;32m   1424\u001b[0m   func_args\u001b[38;5;241m.\u001b[39mappend(placeholder)\n\u001b[0;32m   1426\u001b[0m func_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_spec.py:227\u001b[0m, in \u001b[0;36mTensorSpec.placeholder_value\u001b[1;34m(self, placeholder_context)\u001b[0m\n\u001b[0;32m    225\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01mor\u001b[39;00m placeholder_context\u001b[38;5;241m.\u001b[39mnaming_scope\n\u001b[0;32m    226\u001b[0m context_graph \u001b[38;5;241m=\u001b[39m placeholder_context\u001b[38;5;241m.\u001b[39mcontext_graph\n\u001b[1;32m--> 227\u001b[0m placeholder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_placeholder(context_graph, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m   \u001b[38;5;66;03m# Record the requested/user-specified name in case it's different than\u001b[39;00m\n\u001b[0;32m    230\u001b[0m   \u001b[38;5;66;03m# the uniquified name, for validation when exporting signatures.\u001b[39;00m\n\u001b[0;32m    231\u001b[0m   placeholder\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39m_set_attr(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    232\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_user_specified_name\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    233\u001b[0m       attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue(s\u001b[38;5;241m=\u001b[39mcompat\u001b[38;5;241m.\u001b[39mas_bytes(name)))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_spec.py:255\u001b[0m, in \u001b[0;36mTensorSpec._graph_placeholder\u001b[1;34m(self, graph, name)\u001b[0m\n\u001b[0;32m    253\u001b[0m attrs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: dtype_value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m: shape}\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 255\u001b[0m   op \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39m_create_op_internal(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    256\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlaceholder\u001b[39m\u001b[38;5;124m\"\u001b[39m, [], [dtype], input_types\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m    257\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    259\u001b[0m   \u001b[38;5;66;03m# TODO(b/262413656) Sometimes parameter names are not valid op names, in\u001b[39;00m\n\u001b[0;32m    260\u001b[0m   \u001b[38;5;66;03m# which case an unnamed placeholder is created instead. Update this logic\u001b[39;00m\n\u001b[0;32m    261\u001b[0m   \u001b[38;5;66;03m# to sanitize the name instead of falling back on unnamed placeholders.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m   logging\u001b[38;5;241m.\u001b[39mwarning(e)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:707\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    705\u001b[0m   inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcapture(inp)\n\u001b[0;32m    706\u001b[0m   captured_inputs\u001b[38;5;241m.\u001b[39mappend(inp)\n\u001b[1;32m--> 707\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_create_op_internal(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    708\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[0;32m    709\u001b[0m     compute_device)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3814\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3811\u001b[0m \u001b[38;5;66;03m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3812\u001b[0m \u001b[38;5;66;03m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3814\u001b[0m   ret \u001b[38;5;241m=\u001b[39m Operation(\n\u001b[0;32m   3815\u001b[0m       node_def,\n\u001b[0;32m   3816\u001b[0m       \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3817\u001b[0m       inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m   3818\u001b[0m       output_types\u001b[38;5;241m=\u001b[39mdtypes,\n\u001b[0;32m   3819\u001b[0m       control_inputs\u001b[38;5;241m=\u001b[39mcontrol_inputs,\n\u001b[0;32m   3820\u001b[0m       input_types\u001b[38;5;241m=\u001b[39minput_types,\n\u001b[0;32m   3821\u001b[0m       original_op\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_original_op,\n\u001b[0;32m   3822\u001b[0m       op_def\u001b[38;5;241m=\u001b[39mop_def)\n\u001b[0;32m   3823\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_op_helper(ret, compute_device\u001b[38;5;241m=\u001b[39mcompute_device)\n\u001b[0;32m   3824\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2112\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   2109\u001b[0m     control_input_ops\u001b[38;5;241m.\u001b[39mappend(control_op)\n\u001b[0;32m   2111\u001b[0m \u001b[38;5;66;03m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[1;32m-> 2112\u001b[0m c_op \u001b[38;5;241m=\u001b[39m _create_c_op(g, node_def, inputs, control_input_ops, op_def\u001b[38;5;241m=\u001b[39mop_def)\n\u001b[0;32m   2113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_from_c_op(c_op\u001b[38;5;241m=\u001b[39mc_op, g\u001b[38;5;241m=\u001b[39mg)\n\u001b[0;32m   2115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_op \u001b[38;5;241m=\u001b[39m original_op\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1943\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1941\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1942\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m graph\u001b[38;5;241m.\u001b[39m_c_graph\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;28;01mas\u001b[39;00m c_graph:\n\u001b[1;32m-> 1943\u001b[0m   op_desc \u001b[38;5;241m=\u001b[39m pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_NewOperation(c_graph,\n\u001b[0;32m   1944\u001b[0m                                               compat\u001b[38;5;241m.\u001b[39mas_str(node_def\u001b[38;5;241m.\u001b[39mop),\n\u001b[0;32m   1945\u001b[0m                                               compat\u001b[38;5;241m.\u001b[39mas_str(node_def\u001b[38;5;241m.\u001b[39mname))\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node_def\u001b[38;5;241m.\u001b[39mdevice:\n\u001b[0;32m   1947\u001b[0m   pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_SetDevice(op_desc, compat\u001b[38;5;241m.\u001b[39mas_str(node_def\u001b[38;5;241m.\u001b[39mdevice))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, GRU, LeakyReLU\n",
    "from keras.initializers import he_normal\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_traint, X_testt, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scale = StandardScaler()\n",
    "X_train = scale.fit_transform(X_traint)\n",
    "# new_scaler = joblib.load('C:/Users/RAMU GOPI/AA-Major Project/all models/ML models/ml_saved_models/scalerV1.0.pkl')\n",
    "# X_test = new_scaler.transform(X_test)\n",
    "X_test = scale.transform(X_testt)\n",
    "# Reshape data for GRU input (samples, timesteps, features)\n",
    "time_steps = 1  # Set the time steps to 1 for each sample\n",
    "num_features = X_train.shape[1]  # Number of features in X\n",
    "\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], time_steps, num_features)\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], time_steps, num_features)\n",
    "\n",
    "# GRU_V11 = Sequential()\n",
    "# GRU_V11.add(GRU(256, input_shape=(1, X_train.shape[1]), kernel_initializer=he_normal(), activation=LeakyReLU(alpha=0.03), return_sequences=True))\n",
    "# GRU_V11.add(GRU(128, activation=LeakyReLU(alpha=0.03)))  # Additional GRU layer\n",
    "# #model2.add(Dense(64, activation=LeakyReLU(alpha=0.03)))\n",
    "# GRU_V11.add(Dense(53, activation='sigmoid'))\n",
    "# GRU_V11.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.03), metrics=['accuracy'])\n",
    "# GRU_V11.fit(X_train_reshaped, y_train, epochs=100, batch_size=32, validation_data=(X_test_reshaped, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7f1e1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRU_V11.save('GRU_V11.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d824b712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "GRU = load_model('GRU_V11.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "845184a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 94.27%\n",
      "Testing Accuracy: 94.48%\n"
     ]
    }
   ],
   "source": [
    "#Get training accuracy\n",
    "train_loss, train_accuracy = GRU.evaluate(X_train_reshaped,y_train, verbose=0)\n",
    "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Get testing accuracy\n",
    "test_loss, test_accuracy = GRU.evaluate(X_test_reshaped,y_test, verbose=0)\n",
    "print(f\"Testing Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0b209045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.46810162,  0.51172198, -1.43524375,  2.74656705, -1.19586897,\n",
       "        2.42048112, -0.61171255])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[1005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f62e7afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_Name</th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>pH</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70848</th>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>20</td>\n",
       "      <td>120</td>\n",
       "      <td>5.04</td>\n",
       "      <td>2169.32</td>\n",
       "      <td>23.736364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       State_Name   N   P    K    pH  rainfall  temperature\n",
       "70848           3  90  20  120  5.04   2169.32    23.736364"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c617eb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAMU GOPI\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.55244493,  0.25914583, -0.10657366, -0.0708268 , -0.52218941,\n",
       "        -0.30385077,  0.24392473]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform([[12,80,40,40,5.38,516.68,27.866667]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4ec37a8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n",
      "['apple']\n"
     ]
    }
   ],
   "source": [
    "new_data = np.array([[-1.46810162,  0.51172198, -1.43524375,  2.74656705, -1.19586897,\n",
    "        2.42048112, -0.61171255]])\n",
    "new_data = new_data.reshape(new_data.shape[0], 1,new_data.shape[1])\n",
    "prediction = GRU.predict(new_data)\n",
    "predicted_class = np.argmax(prediction, axis=1)\n",
    "predicted_crop = encoder.inverse_transform(predicted_class)\n",
    "print(predicted_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4a993a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sweetpotato'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.inverse_transform(y_test)[1005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1dad3af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02779010",
   "metadata": {},
   "source": [
    "# Ensemble Voting Classifier try running in Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcd86948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikeras in c:\\users\\ramu gopi\\anaconda3\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: packaging>=0.21 in c:\\users\\ramu gopi\\anaconda3\\lib\\site-packages (from scikeras) (23.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\ramu gopi\\anaconda3\\lib\\site-packages (from scikeras) (1.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem<0.32,>=0.23.1 in c:\\users\\ramu gopi\\anaconda3\\lib\\site-packages (from scikeras) (0.31.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\ramu gopi\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\ramu gopi\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\ramu gopi\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ramu gopi\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "990afe2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAMU GOPI\\AppData\\Local\\Temp\\ipykernel_15380\\2262802088.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['State_Name'] = le.fit_transform(data['State_Name'])\n",
      "C:\\Users\\RAMU GOPI\\AppData\\Local\\Temp\\ipykernel_15380\\2262802088.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Crop'] = output_encoder.fit_transform(data['Crop'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, GRU, Dense, LeakyReLU, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.initializers import he_normal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "dataset = pd.read_csv(\"D:/SEM/7th sem/major project/review-2.0/archive10MB/Crop_production.csv\")\n",
    "#dataset = pd.read_csv(\"Crop_production.csv\")  # Replace with your dataset path\n",
    "columns = ['State_Name', 'N', 'P', 'K', 'pH', 'rainfall', 'temperature', 'Crop']\n",
    "data = dataset[columns]\n",
    "\n",
    "# Encoding categorical columns\n",
    "le = LabelEncoder()\n",
    "data['State_Name'] = le.fit_transform(data['State_Name'])\n",
    "\n",
    "# Assuming 'Crop' is the output column, encode it\n",
    "output_encoder = LabelEncoder()\n",
    "data['Crop'] = output_encoder.fit_transform(data['Crop'])\n",
    "num_classes = len(output_encoder.classes_)\n",
    "\n",
    "# Split dataset into features (X) and labels (y)\n",
    "X = data.drop(columns=['Crop'])\n",
    "y = data['Crop']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scale = StandardScaler()\n",
    "X_train = scale.fit_transform(X_train)\n",
    "X_test = scale.transform(X_test)\n",
    "time_steps = 1  # Set the time steps to 1 for each sample\n",
    "num_features = X_train.shape[1]  # Number of features in X\n",
    "\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], time_steps, num_features)\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], time_steps, num_features)\n",
    "\n",
    "\n",
    "# # Example dataset (replace this with your dataset)\n",
    "# X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to create LSTM model\n",
    "def create_lstm_model():\n",
    "    LSTM_V11 = Sequential()\n",
    "    LSTM_V11.add(LSTM(256, input_shape=(1, X_train_reshaped.shape[2]), activation='relu'))\n",
    "    #model.add(Dense(128,activation = 'relu'))\n",
    "    LSTM_V11.add(Dense(53, activation='softmax'))  # Adjust output units and activation for multiclass\n",
    "    # Compile the model\n",
    "    LSTM_V11.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return LSTM_V11\n",
    "\n",
    "\n",
    "\n",
    "# Function to create GRU model\n",
    "def create_gru_model():\n",
    "    GRU_V11 = Sequential()\n",
    "    GRU_V11.add(GRU(256, input_shape=(1, X_train_reshaped.shape[2]), kernel_initializer=he_normal(), activation=LeakyReLU(alpha=0.03), return_sequences=True))\n",
    "    GRU_V11.add(GRU(128, activation=LeakyReLU(alpha=0.03)))  # Additional GRU layer\n",
    "    #model2.add(Dense(64, activation=LeakyReLU(alpha=0.03)))\n",
    "    GRU_V11.add(Dense(53, activation='sigmoid'))\n",
    "    GRU_V11.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.03), metrics=['accuracy'])\n",
    "    return GRU_V11\n",
    "def create_ann_model():\n",
    "    ANN_V11 = Sequential()\n",
    "    # Add layers\n",
    "    ANN_V11.add(Dense(128, input_shape=(1, X_train_reshaped.shape[2]), activation='relu'))\n",
    "    ANN_V11.add(Dense(64, activation='relu'))\n",
    "    ANN_V11.add(Dense(32, activation='relu'))\n",
    "    ANN_V11.add(Dense(53, activation='softmax'))  # Softmax for multi-class classification\n",
    "    # Compile the model\n",
    "    ANN_V11.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return ANN_V11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605dc216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the ANN model\n",
    "ann_classifier = KerasClassifier(build_fn=create_ann_model, epochs=100, batch_size=32, verbose=1)\n",
    "ann_classifier.fit(X_train_reshaped, y_train)\n",
    "\n",
    "# Train the LSTM model\n",
    "lstm_classifier = KerasClassifier(build_fn=create_lstm_model, epochs=100, batch_size=32, verbose=1)\n",
    "lstm_classifier.fit(X_train_reshaped, y_train)\n",
    "\n",
    "# Train the GRU model\n",
    "gru_classifier = KerasClassifier(build_fn=create_gru_model, epochs=100, batch_size=32, verbose=1)\n",
    "gru_classifier.fit(X_train_reshaped, y_train)\n",
    "import joblib\n",
    "# Save the models\n",
    "joblib.dump(ann_classifier, 'ann_classifier_100epV13.pkl')\n",
    "joblib.dump(lstm_classifier, 'lstm_classifier_100epV13.pkl')\n",
    "joblib.dump(gru_classifier, 'gru_classifier_100epV13.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d359a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann_classifier = joblib.load('ann_classifier_100epV13.pkl')\n",
    "# lstm_classifier = joblib.load('lstm_classifier_100epV13.pkl')\n",
    "# gru_classifier = joblib.load('gru_classifier_100epV13.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e978402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the trained models into KerasClassifier\n",
    "ann_classifier = KerasClassifier(build_fn=create_ann_model, epochs=100, batch_size=32, verbose=1)\n",
    "lstm_classifier = KerasClassifier(build_fn=create_lstm_model, epochs=100, batch_size=32, verbose=1)\n",
    "gru_classifier = KerasClassifier(build_fn=create_gru_model, epochs=100, batch_size=32, verbose=1)\n",
    "\n",
    "# Initialize VotingClassifier\n",
    "models = [('LSTM', lstm_classifier), ('GRU', gru_classifier),('ANN', ann_classifier)]\n",
    "voting_classifier = VotingClassifier(estimators=models, voting='soft') # 'soft' for probabilities\n",
    "\n",
    "# Train the VotingClassifier\n",
    "voting_classifier.fit(X_train_reshaped, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9662e29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the VotingClassifier\n",
    "accuracy = voting_classifier.score(X_test_reshaped, y_test)\n",
    "print(f\"Voting Classifier Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbad271",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "import joblib\n",
    "joblib.dump(voting_classifier, 'voting_classifier_100epV12.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f605a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAMU GOPI\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\RAMU GOPI\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator OrdinalEncoder from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\RAMU GOPI\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\RAMU GOPI\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator FunctionTransformer from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\RAMU GOPI\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator OrdinalEncoder from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\RAMU GOPI\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\RAMU GOPI\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator FunctionTransformer from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\RAMU GOPI\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator OrdinalEncoder from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\RAMU GOPI\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\RAMU GOPI\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator FunctionTransformer from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\RAMU GOPI\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator VotingClassifier from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 3s 4ms/step\n",
      "625/625 [==============================] - 3s 4ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "Voting Classifier Accuracy: 94.82%\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "#voting_classifier = joblib.load('voting_classifier_V12.pkl')\n",
    "voting_classifier = joblib.load('voting_classifier_100epV12.pkl')\n",
    "# Make predictions on new data\n",
    "X_new = X_test_reshaped\n",
    "# Evaluate the VotingClassifier\n",
    "accuracy = voting_classifier.score(X_new, y_test)\n",
    "print(f\"Voting Classifier Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c5e6c128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.08362218,  0.00593459, -0.10503347,  0.63419203,\n",
       "          0.90616119,  0.39659741,  0.47473113]],\n",
       "\n",
       "       [[ 1.28776009,  0.00593459, -0.10503347,  0.10609828,\n",
       "         -0.20434531, -1.03483351, -0.83080451]]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a2ac5bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.08362218,  0.00593459, -0.10503347,  0.63419203,\n",
       "          0.90616119,  0.39659741,  0.47473113]],\n",
       "\n",
       "       [[ 1.08362218,  0.00593459, -0.10503347,  0.63419203,\n",
       "          0.90616119,  0.39659741,  0.47473113]]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = [[list(X_test[0:1][0])],[list(X_test[0:1][0])]]\n",
    "new_data = np.array(new_data)\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9133874b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8f1a53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1, 7)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new_data = new_data.reshape(1,7)\n",
    "new_data = new_data.reshape(2,1,7)\n",
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "28d0512f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([14, 14], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_classifier.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4796b329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "cashewnuts\n",
      "cashewnuts\n"
     ]
    }
   ],
   "source": [
    "print(output_encoder.inverse_transform(voting_classifier.predict(new_data))[0])\n",
    "print(output_encoder.inverse_transform(y_test[:1])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3136875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_voting_predictions(data):#data = list(7 params)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fe9d9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAMU GOPI\\AppData\\Local\\Temp\\ipykernel_20388\\4180085951.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['State_Name'] = le.fit_transform(data['State_Name'])\n",
      "C:\\Users\\RAMU GOPI\\AppData\\Local\\Temp\\ipykernel_20388\\4180085951.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Crop'] = output_encoder.fit_transform(data['Crop'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, GRU, Dense, LeakyReLU, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.initializers import he_normal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "dataset = pd.read_csv(\"D:/SEM/7th sem/major project/review-2.0/archive10MB/Crop_production.csv\")\n",
    "#dataset = pd.read_csv(\"Crop_production.csv\")  # Replace with your dataset path\n",
    "columns = ['State_Name', 'N', 'P', 'K', 'pH', 'rainfall', 'temperature', 'Crop']\n",
    "data = dataset[columns]\n",
    "\n",
    "# Encoding categorical columns\n",
    "le = LabelEncoder()\n",
    "data['State_Name'] = le.fit_transform(data['State_Name'])\n",
    "\n",
    "# Assuming 'Crop' is the output column, encode it\n",
    "output_encoder = LabelEncoder()\n",
    "data['Crop'] = output_encoder.fit_transform(data['Crop'])\n",
    "num_classes = len(output_encoder.classes_)\n",
    "\n",
    "# Split dataset into features (X) and labels (y)\n",
    "X = data.drop(columns=['Crop'])\n",
    "y = data['Crop']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#scale = StandardScaler()\n",
    "# X_train = scale.fit_transform(X_train)\n",
    "import joblib\n",
    "scaler = joblib.load(\"C:/Users/RAMU GOPI/AA-Major Project/all models/ML models/ml_saved_models/scalerV1.0.pkl\")\n",
    "X_test = scaler.transform(X_test)\n",
    "time_steps = 1  # Set the time steps to 1 for each sample\n",
    "num_features = X_train.shape[1]  # Number of features in X\n",
    "\n",
    "X_train_reshaped = X_train.to_numpy().reshape(X_train.shape[0], time_steps, num_features)\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], time_steps, num_features)\n",
    "def create_lstm_model():\n",
    "    LSTM_V10 = Sequential()\n",
    "    LSTM_V10.add(LSTM(256, input_shape=(1, X_train_reshaped.shape[2]), activation='relu'))\n",
    "    #model.add(Dense(128,activation = 'relu'))\n",
    "    LSTM_V10.add(Dense(53, activation='softmax'))  # Adjust output units and activation for multiclass\n",
    "    # Compile the model\n",
    "    LSTM_V10.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return LSTM_V10\n",
    "\n",
    "\n",
    "\n",
    "# Function to create GRU model\n",
    "def create_gru_model():\n",
    "    GRU_V10 = Sequential()\n",
    "    GRU_V10.add(GRU(256, input_shape=(1, X_train_reshaped.shape[2]), kernel_initializer=he_normal(), activation=LeakyReLU(alpha=0.03), return_sequences=True))\n",
    "    GRU_V10.add(GRU(128, activation=LeakyReLU(alpha=0.03)))  # Additional GRU layer\n",
    "    #model2.add(Dense(64, activation=LeakyReLU(alpha=0.03)))\n",
    "    GRU_V10.add(Dense(53, activation='sigmoid'))\n",
    "    GRU_V10.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.03), metrics=['accuracy'])\n",
    "    return GRU_V10\n",
    "def create_ann_model():\n",
    "    ANN_V10 = Sequential()\n",
    "    # Add layers\n",
    "    ANN_V10.add(Dense(128, input_shape=(1, X_train_reshaped.shape[2]), activation='relu'))\n",
    "    ANN_V10.add(Dense(64, activation='relu'))\n",
    "    ANN_V10.add(Dense(32, activation='relu'))\n",
    "    ANN_V10.add(Dense(53, activation='softmax'))  # Softmax for multi-class classification\n",
    "    # Compile the model\n",
    "    ANN_V10.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return ANN_V10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b51f004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e335842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAMU GOPI\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\RAMU GOPI\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator OrdinalEncoder from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\RAMU GOPI\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\RAMU GOPI\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator FunctionTransformer from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\RAMU GOPI\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator OrdinalEncoder from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\RAMU GOPI\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\RAMU GOPI\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator FunctionTransformer from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\RAMU GOPI\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator OrdinalEncoder from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\RAMU GOPI\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\RAMU GOPI\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator FunctionTransformer from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\RAMU GOPI\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator VotingClassifier from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 3s 4ms/step\n",
      "625/625 [==============================] - 3s 4ms/step\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "Voting Classifier Accuracy: 94.82%\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "#voting_classifier = joblib.load('voting_classifier_V12.pkl')\n",
    "voting_classifier = joblib.load('voting_classifier_100epV12.pkl')\n",
    "# Make predictions on new data\n",
    "X_new = X_test_reshaped\n",
    "# Evaluate the VotingClassifier\n",
    "accuracy = voting_classifier.score(X_new, y_test)\n",
    "print(f\"Voting Classifier Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "760b0cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['ann_classifier_100epV13',\"lstm_classifier_100epV13\",'gru_classifier_100epV13',\"voting_classifier_100epV12\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "78065e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib,shutil,os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import load_model\n",
    "crops = ['apple', 'arecanut', 'ashgourd', 'banana', 'barley', 'beetroot',\n",
    "       'bittergourd', 'blackgram', 'blackpepper', 'bottlegourd',\n",
    "       'brinjal', 'cabbage', 'cardamom', 'carrot', 'cashewnuts',\n",
    "       'cauliflower', 'coffee', 'coriander', 'cotton', 'cucumber',\n",
    "       'drumstick', 'garlic', 'ginger', 'grapes', 'horsegram',\n",
    "       'jackfruit', 'jowar', 'jute', 'ladyfinger', 'maize', 'mango',\n",
    "       'moong', 'onion', 'orange', 'papaya', 'pineapple', 'pomegranate',\n",
    "       'potato', 'pumpkin', 'radish', 'ragi', 'rapeseed', 'rice',\n",
    "       'ridgegourd', 'sesamum', 'soyabean', 'sunflower', 'sweetpotato',\n",
    "       'tapioca', 'tomato', 'turmeric', 'watermelon', 'wheat']\n",
    "states = ['andaman and nicobar islands', 'andhra pradesh',\n",
    "       'arunachal pradesh', 'assam', 'bihar', 'chandigarh',\n",
    "       'chhattisgarh', 'dadra and nagar haveli', 'goa', 'gujarat',\n",
    "       'haryana', 'himachal pradesh', 'jammu and kashmir', 'jharkhand',\n",
    "       'karnataka', 'kerala', 'madhya pradesh', 'maharashtra', 'manipur',\n",
    "       'meghalaya', 'mizoram', 'nagaland', 'odisha', 'puducherry',\n",
    "       'punjab', 'rajasthan', 'sikkim', 'tamil nadu', 'telangana',\n",
    "       'tripura', 'uttar pradesh', 'uttarakhand', 'west bengal']\n",
    "# def prediction(model_name,new_data):\n",
    "#     #temp = #extract temperature from state\n",
    "#     new_data[0] = states.index(new_data[0])\n",
    "#     new_scaler = joblib.load('C:/Users/RAMU GOPI/AA-Major Project/all models/ML models/ml_saved_models/scalerV1.0.pkl')\n",
    "#     new_data = new_scaler.transform([new_data])\n",
    "#     new_data = new_data.reshape(1,1,len(new_data[0]))\n",
    "#     model = load_model(f\"D:/SEM/7th sem/major project/review-2.0/models-V1.1/DL models/ensemble_3 models/{name}.pkl\")\n",
    "#     crop = crops[model.predict(new_data)[0]]\n",
    "#     return crop\n",
    "# for name in models:\n",
    "#     crop = prediction(name,['andaman and nicobar islands',100,40,140,5.86,1925.68,27.0])\n",
    "#     print(name,\" : \",crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dbc4c6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "def data_for_ann_cnn(new_data):\n",
    "    new_data[0] = states.index(new_data[0])\n",
    "    new_scaler = joblib.load('C:/Users/RAMU GOPI/AA-Major Project/all models/ML models/ml_saved_models/scalerV1.0.pkl')\n",
    "    new_data = new_scaler.transform([new_data])\n",
    "    return new_data\n",
    "def data_for_LSTM(new_data):\n",
    "    new_data[0] = states.index(new_data[0])\n",
    "    new_scaler = joblib.load('C:/Users/RAMU GOPI/AA-Major Project/all models/ML models/ml_saved_models/scalerV1.0.pkl')\n",
    "    new_data = new_scaler.transform([new_data])\n",
    "    new_data = new_data.reshape(new_data.shape[0], 1,new_data.shape[1])\n",
    "    return new_data\n",
    "def prediction_from_ann(new_data):\n",
    "    ann_model = load_model(\"C:/Users/RAMU GOPI/AA-Major Project/all models/DL models/ANN_V10.keras\")\n",
    "    return crops[np.argmax(ann_model.predict(new_data),axis = 1)[0]]\n",
    "def prediction_from_cnn(new_data):\n",
    "    cnn_model = load_model(\"C:/Users/RAMU GOPI/AA-Major Project/all models/DL models/CNN_V10.keras\")\n",
    "    return crops[np.argmax(cnn_model.predict(new_data),axis = 1)[0]]\n",
    "def prediction_from_lstm(new_data):\n",
    "    lstm_model = load_model(\"C:/Users/RAMU GOPI/AA-Major Project/all models/DL models/LSTM_V11.keras\")\n",
    "    return crops[np.argmax(lstm_model.predict(new_data),axis = 1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ddf9bff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_data = data_for_ann(['andaman and nicobar islands',100,40,140,5.86,1925.68,27.0])\n",
    "# print(\"recommended Crop from ANN: \",prediction_from_ann(new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7107e6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>State_Name</th>\n",
       "      <th>Crop_Type</th>\n",
       "      <th>Crop</th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>pH</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>temperature</th>\n",
       "      <th>Area_in_hectares</th>\n",
       "      <th>Production_in_tons</th>\n",
       "      <th>Yield_ton_per_hec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>500</td>\n",
       "      <td>assam</td>\n",
       "      <td>whole year</td>\n",
       "      <td>onion</td>\n",
       "      <td>120</td>\n",
       "      <td>60</td>\n",
       "      <td>65</td>\n",
       "      <td>6.12</td>\n",
       "      <td>2169.32</td>\n",
       "      <td>23.736364</td>\n",
       "      <td>188.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>2.680851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0 State_Name   Crop_Type   Crop    N   P   K    pH  rainfall  \\\n",
       "500         500      assam  whole year  onion  120  60  65  6.12   2169.32   \n",
       "\n",
       "     temperature  Area_in_hectares  Production_in_tons  Yield_ton_per_hec  \n",
       "500    23.736364             188.0               504.0           2.680851  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[500:501,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a2ae9976",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAMU GOPI\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 341ms/step\n",
      "recommended Crop from ANN:  onion\n"
     ]
    }
   ],
   "source": [
    "new_data = data_for_ann_cnn([\"assam\",120,60,65,6.12,2169.32,23.736364])\n",
    "print(\"recommended Crop from ANN: \",prediction_from_ann(new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f02fde88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAMU GOPI\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 648 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002B9033E4EA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "recommended Crop from CNN:  rice\n"
     ]
    }
   ],
   "source": [
    "new_data = data_for_ann_cnn([\"jammu and kashmir\",80,40,40,5.38,516.68,27.866667])\n",
    "print(\"recommended Crop from CNN: \",prediction_from_cnn(new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "956269c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAMU GOPI\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 647 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002B90343C9A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 565ms/step\n",
      "recommended Crop from LSTM:  rice\n"
     ]
    }
   ],
   "source": [
    "new_data = data_for_LSTM([\"jammu and kashmir\",80,40,40,5.38,516.68,27.866667])\n",
    "print(\"recommended Crop from LSTM: \",prediction_from_lstm(new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "93415c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6b5eac11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30059    14\n",
       "10182     4\n",
       "16280    46\n",
       "54944    47\n",
       "98212    42\n",
       "         ..\n",
       "46645    30\n",
       "3676     26\n",
       "44340    34\n",
       "16423    44\n",
       "29478    50\n",
       "Name: Crop, Length: 19970, dtype: int32"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f178abb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_Name</th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>pH</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30059</th>\n",
       "      <td>28</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "      <td>6.1</td>\n",
       "      <td>942.8</td>\n",
       "      <td>28.994545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       State_Name   N   P   K   pH  rainfall  temperature\n",
       "30059          28  70  40  60  6.1     942.8    28.994545"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[:1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38c9930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "506919b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.08271776,  0.00594187, -0.10657366,  0.63241418,  0.90177418,\n",
       "         0.40128621,  0.47614855]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_scaler = joblib.load('C:/Users/RAMU GOPI/AA-Major Project/all models/ML models/ml_saved_models/scalerV1.0.pkl')\n",
    "new_data = new_scaler.transform(X_test.iloc[:1,])\n",
    "# new_data = new_data.reshape(new_data.shape[0], 1,new_data.shape[1])\n",
    "# prediction_from_gru(new_data)\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d8b776b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.08362218,  0.00593459, -0.10503347, ...,  0.90616119,\n",
       "         0.39659741,  0.47473113],\n",
       "       [ 1.28776009,  0.00593459, -0.10503347, ..., -0.20434531,\n",
       "        -1.03483351, -0.83080451],\n",
       "       [ 0.98155323, -0.4998528 ,  1.22517681, ..., -0.20434531,\n",
       "        -0.66794972,  0.59294262],\n",
       "       ...,\n",
       "       [-0.14120524, -0.4998528 ,  0.56007167, ...,  0.58887362,\n",
       "         0.67526672,  0.4031656 ],\n",
       "       [ 0.98155323, -1.00564019, -1.76779632, ...,  1.69938012,\n",
       "        -0.66794972,  0.59294262],\n",
       "       [ 0.77741533, -1.13208703,  1.22517681, ..., -1.15620802,\n",
       "        -0.24133222,  0.38194013]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c531ce73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAMU GOPI\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 914ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bittergourd'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prediction_from_gru(new_data):\n",
    "    gru_model = load_model(\"C:/Users/RAMU GOPI/AA-Major Project/all models/DL models/GRU_V11.keras\")\n",
    "    return crops[np.argmax(gru_model.predict(new_data),axis = 1)[0]]\n",
    "new_data = data_for_LSTM([\"jammu and kashmir\",60,30,30,6.11,293.36,14.700000])\n",
    "prediction_from_gru(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "275c1541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 875ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'barley'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_model = load_model(\"C:/Users/RAMU GOPI/AA-Major Project/all models/DL models/GRU_V11.keras\")\n",
    "crops[np.argmax(gru_model.predict(new_data),axis = 1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "791fbdd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 7)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "19d72f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>State_Name</th>\n",
       "      <th>Crop_Type</th>\n",
       "      <th>Crop</th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>pH</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>temperature</th>\n",
       "      <th>Area_in_hectares</th>\n",
       "      <th>Production_in_tons</th>\n",
       "      <th>Yield_ton_per_hec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>1502</td>\n",
       "      <td>jammu and kashmir</td>\n",
       "      <td>kharif</td>\n",
       "      <td>rice</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>5.38</td>\n",
       "      <td>516.68</td>\n",
       "      <td>27.866667</td>\n",
       "      <td>27897.0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>0.022440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>1503</td>\n",
       "      <td>jammu and kashmir</td>\n",
       "      <td>rabi</td>\n",
       "      <td>wheat</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>6.11</td>\n",
       "      <td>293.36</td>\n",
       "      <td>14.700000</td>\n",
       "      <td>645.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>0.899225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0         State_Name Crop_Type   Crop   N   P   K    pH  \\\n",
       "1502        1502  jammu and kashmir    kharif   rice  80  40  40  5.38   \n",
       "1503        1503  jammu and kashmir      rabi  wheat  60  30  30  6.11   \n",
       "\n",
       "      rainfall  temperature  Area_in_hectares  Production_in_tons  \\\n",
       "1502    516.68    27.866667           27897.0               626.0   \n",
       "1503    293.36    14.700000             645.0               580.0   \n",
       "\n",
       "      Yield_ton_per_hec  \n",
       "1502           0.022440  \n",
       "1503           0.899225  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[1502:1504,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8b6c6d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAMU GOPI\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 698ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'barley'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = data_for_LSTM([\"jammu and kashmir\",80,40,40,5.38,516.68,27.866667])\n",
    "prediction_from_gru(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4aa4d16e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.47222395,  1.27196166,  1.22181793,  0.80822442,\n",
       "          0.94132873,  2.43091308, -0.6064814 ]]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8cef12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
